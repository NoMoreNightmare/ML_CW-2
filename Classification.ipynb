{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pCR (outcome)</th>\n",
       "      <th>RelapseFreeSurvival (outcome)</th>\n",
       "      <th>Age</th>\n",
       "      <th>ER</th>\n",
       "      <th>PgR</th>\n",
       "      <th>HER2</th>\n",
       "      <th>TrippleNegative</th>\n",
       "      <th>ChemoGrade</th>\n",
       "      <th>Proliferation</th>\n",
       "      <th>...</th>\n",
       "      <th>original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_SmallAreaLowGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_ZoneEntropy</th>\n",
       "      <th>original_glszm_ZonePercentage</th>\n",
       "      <th>original_glszm_ZoneVariance</th>\n",
       "      <th>original_ngtdm_Busyness</th>\n",
       "      <th>original_ngtdm_Coarseness</th>\n",
       "      <th>original_ngtdm_Complexity</th>\n",
       "      <th>original_ngtdm_Contrast</th>\n",
       "      <th>original_ngtdm_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRG002174</td>\n",
       "      <td>1</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517172</td>\n",
       "      <td>0.375126</td>\n",
       "      <td>3.325332</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>3.880772e+06</td>\n",
       "      <td>473.464852</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.182615</td>\n",
       "      <td>0.030508</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRG002178</td>\n",
       "      <td>0</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444391</td>\n",
       "      <td>0.444391</td>\n",
       "      <td>3.032144</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>2.372010e+06</td>\n",
       "      <td>59.459710</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.032012</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.003685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRG002204</td>\n",
       "      <td>1</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534549</td>\n",
       "      <td>0.534549</td>\n",
       "      <td>2.485848</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>1.540027e+06</td>\n",
       "      <td>33.935384</td>\n",
       "      <td>0.007584</td>\n",
       "      <td>0.024062</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.006447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRG002206</td>\n",
       "      <td>0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506185</td>\n",
       "      <td>0.506185</td>\n",
       "      <td>2.606255</td>\n",
       "      <td>0.003755</td>\n",
       "      <td>6.936741e+06</td>\n",
       "      <td>46.859265</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.013707</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.004543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRG002210</td>\n",
       "      <td>0</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462282</td>\n",
       "      <td>0.462282</td>\n",
       "      <td>2.809279</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>1.265399e+06</td>\n",
       "      <td>39.621023</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.005626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>TRG002955</td>\n",
       "      <td>1</td>\n",
       "      <td>49.250000</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439568</td>\n",
       "      <td>0.439568</td>\n",
       "      <td>3.056046</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>1.671271e+07</td>\n",
       "      <td>79.989003</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.024716</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.003078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>TRG002958</td>\n",
       "      <td>0</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>53.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527779</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>2.132007e+05</td>\n",
       "      <td>0.996746</td>\n",
       "      <td>0.252582</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.231059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>TRG002961</td>\n",
       "      <td>0</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>68.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313693</td>\n",
       "      <td>0.313693</td>\n",
       "      <td>3.573557</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>2.008034e+07</td>\n",
       "      <td>204.864200</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.054063</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.001368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>TRG002962</td>\n",
       "      <td>0</td>\n",
       "      <td>46.916667</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670229</td>\n",
       "      <td>0.670229</td>\n",
       "      <td>1.857045</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>5.609262e+05</td>\n",
       "      <td>9.609163</td>\n",
       "      <td>0.026591</td>\n",
       "      <td>0.018682</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.022676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>TRG002963</td>\n",
       "      <td>1</td>\n",
       "      <td>46.750000</td>\n",
       "      <td>55.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552491</td>\n",
       "      <td>0.552491</td>\n",
       "      <td>2.671677</td>\n",
       "      <td>0.005390</td>\n",
       "      <td>1.570529e+06</td>\n",
       "      <td>72.281874</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.055151</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.003425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  pCR (outcome)  RelapseFreeSurvival (outcome)   Age  ER  PgR  \\\n",
       "0    TRG002174              1                     144.000000  41.0   0    0   \n",
       "1    TRG002178              0                     142.000000  39.0   1    1   \n",
       "2    TRG002204              1                     135.000000  31.0   0    0   \n",
       "3    TRG002206              0                      12.000000  35.0   0    0   \n",
       "4    TRG002210              0                     109.000000  61.0   1    0   \n",
       "..         ...            ...                            ...   ...  ..  ...   \n",
       "395  TRG002955              1                      49.250000  46.1   0    0   \n",
       "396  TRG002958              0                      48.500000  53.3   0    0   \n",
       "397  TRG002961              0                      47.500000  68.8   1    0   \n",
       "398  TRG002962              0                      46.916667  46.0   1    0   \n",
       "399  TRG002963              1                      46.750000  55.3   0    0   \n",
       "\n",
       "     HER2  TrippleNegative  ChemoGrade  Proliferation  ...  \\\n",
       "0       0                1           3              3  ...   \n",
       "1       0                0           3              3  ...   \n",
       "2       0                1           2              1  ...   \n",
       "3       0                1           3              3  ...   \n",
       "4       0                0           2              1  ...   \n",
       "..    ...              ...         ...            ...  ...   \n",
       "395     0                1           3              3  ...   \n",
       "396     0                1           2              1  ...   \n",
       "397     0                0           3              3  ...   \n",
       "398     0                0           2              1  ...   \n",
       "399     1                0           2              1  ...   \n",
       "\n",
       "     original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
       "0                                         0.517172   \n",
       "1                                         0.444391   \n",
       "2                                         0.534549   \n",
       "3                                         0.506185   \n",
       "4                                         0.462282   \n",
       "..                                             ...   \n",
       "395                                       0.439568   \n",
       "396                                       0.527779   \n",
       "397                                       0.313693   \n",
       "398                                       0.670229   \n",
       "399                                       0.552491   \n",
       "\n",
       "     original_glszm_SmallAreaLowGrayLevelEmphasis  original_glszm_ZoneEntropy  \\\n",
       "0                                        0.375126                    3.325332   \n",
       "1                                        0.444391                    3.032144   \n",
       "2                                        0.534549                    2.485848   \n",
       "3                                        0.506185                    2.606255   \n",
       "4                                        0.462282                    2.809279   \n",
       "..                                            ...                         ...   \n",
       "395                                      0.439568                    3.056046   \n",
       "396                                      0.527778                    1.500000   \n",
       "397                                      0.313693                    3.573557   \n",
       "398                                      0.670229                    1.857045   \n",
       "399                                      0.552491                    2.671677   \n",
       "\n",
       "     original_glszm_ZonePercentage  original_glszm_ZoneVariance  \\\n",
       "0                         0.002314                 3.880772e+06   \n",
       "1                         0.005612                 2.372010e+06   \n",
       "2                         0.006752                 1.540027e+06   \n",
       "3                         0.003755                 6.936741e+06   \n",
       "4                         0.006521                 1.265399e+06   \n",
       "..                             ...                          ...   \n",
       "395                       0.001339                 1.671271e+07   \n",
       "396                       0.003728                 2.132007e+05   \n",
       "397                       0.001112                 2.008034e+07   \n",
       "398                       0.006706                 5.609262e+05   \n",
       "399                       0.005390                 1.570529e+06   \n",
       "\n",
       "     original_ngtdm_Busyness  original_ngtdm_Coarseness  \\\n",
       "0                 473.464852                   0.000768   \n",
       "1                  59.459710                   0.004383   \n",
       "2                  33.935384                   0.007584   \n",
       "3                  46.859265                   0.005424   \n",
       "4                  39.621023                   0.006585   \n",
       "..                       ...                        ...   \n",
       "395                79.989003                   0.003282   \n",
       "396                 0.996746                   0.252582   \n",
       "397               204.864200                   0.001372   \n",
       "398                 9.609163                   0.026591   \n",
       "399                72.281874                   0.003759   \n",
       "\n",
       "     original_ngtdm_Complexity  original_ngtdm_Contrast  \\\n",
       "0                     0.182615                 0.030508   \n",
       "1                     0.032012                 0.001006   \n",
       "2                     0.024062                 0.000529   \n",
       "3                     0.013707                 0.000178   \n",
       "4                     0.034148                 0.001083   \n",
       "..                         ...                      ...   \n",
       "395                   0.024716                 0.000812   \n",
       "396                   0.007380                 0.000037   \n",
       "397                   0.054063                 0.003697   \n",
       "398                   0.018682                 0.000311   \n",
       "399                   0.055151                 0.003054   \n",
       "\n",
       "     original_ngtdm_Strength  \n",
       "0                   0.000758  \n",
       "1                   0.003685  \n",
       "2                   0.006447  \n",
       "3                   0.004543  \n",
       "4                   0.005626  \n",
       "..                       ...  \n",
       "395                 0.003078  \n",
       "396                 0.231059  \n",
       "397                 0.001368  \n",
       "398                 0.022676  \n",
       "399                 0.003425  \n",
       "\n",
       "[395 rows x 120 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset=pd.read_excel(\"Data/trainDataset.xls\")\n",
    "dataset=dataset[dataset[\"pCR (outcome)\"]!=999]\n",
    "dataset.head(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Removing duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.drop_duplicates(inplace=True) #because with 119 features, it is unlikely that exact same data happens in real world, it is useless for training and testing; hence remove it before dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    299\n",
       "1     96\n",
       "Name: pCR (outcome), dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['pCR (outcome)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=dataset['pCR (outcome)']\n",
    "X=dataset.drop(['pCR (outcome)','RelapseFreeSurvival (outcome)'],axis=1)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,stratify=y,random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### drop columns that are not applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class columnDropperTransformer(): #https://stackoverflow.com/questions/68402691/adding-dropping-column-instance-into-a-pipeline\n",
    "    def __init__(self,columns):\n",
    "        self.columns=columns\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "        return X.drop(self.columns,axis=1)\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return X.drop(self.columns,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                               0\n",
       "pCR (outcome)                    0\n",
       "RelapseFreeSurvival (outcome)    0\n",
       "Age                              0\n",
       "ER                               0\n",
       "                                ..\n",
       "original_ngtdm_Busyness          0\n",
       "original_ngtdm_Coarseness        0\n",
       "original_ngtdm_Complexity        0\n",
       "original_ngtdm_Contrast          0\n",
       "original_ngtdm_Strength          0\n",
       "Length: 120, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.impute import KNNImputer\n",
    "\n",
    "# names=X_train.columns\n",
    "\n",
    "# imp=KNNImputer(missing_values=np.nan,n_neighbors=200)\n",
    "# # X_train[:]=imp.fit_transform(X_train)\n",
    "# # X_test[:]=imp.transform(X_test)\n",
    "# X_train=imp.fit_transform(X_train)\n",
    "# X_test=imp.transform(X_test)\n",
    "\n",
    "# imp.missing_values=np.float64(999)\n",
    "# # X_train[:]=imp.fit_transform(X_train)\n",
    "# # X_test[:]=imp.transform(X_test)\n",
    "# X_train=imp.fit_transform(X_train)\n",
    "# X_test=imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class outlierHandlingWithDev():\n",
    "    def fit(self,X,y=None):\n",
    "        self.mean=np.zeros(len(X[0]))\n",
    "        self.std=np.zeros(len(X[0]))\n",
    "        for i in range(len(X[0])):\n",
    "            self.mean[i]=X[:,i].mean()\n",
    "            self.std[i]=X[:,i].std()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "        for i in range(len(X)):\n",
    "            for j in range(len(X[i])):\n",
    "                if np.abs(X[i][j]-self.mean[j])>3*self.std[j]:\n",
    "                    X[i][j]=999\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        self.fit(X,y)\n",
    "        return self.transform(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import Binarizer\n",
    "# datasetCopy=dataset.iloc[:,3].values.reshape(-1,1)\n",
    "# transformor=Binarizer(threshold=40).fit(datasetCopy)\n",
    "# transformor\n",
    "# x1=transformor.transform(datasetCopy)\n",
    "# dataset.iloc[:,3]=x1\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# datasetCopy=dataset.iloc[:,3].values.reshape(-1,1)\n",
    "# transformor=Binarizer(threshold=40).fit(datasetCopy)\n",
    "# transformor\n",
    "# x1=transformor.transform(datasetCopy)\n",
    "# dataset.iloc[:,3]=x1\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import KBinsDiscretizer\n",
    "# datasetCopy=dataset.iloc[:,3].values.reshape(-1,1)\n",
    "# # 不能导入一维，所以reshape\n",
    "# est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')\n",
    "# est.fit(datasetCopy)\n",
    "# Xt = est.transform(datasetCopy)\n",
    "# set(Xt.ravel())\n",
    "# dataset.iloc[:,3]=Xt\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler=MinMaxScaler()\n",
    "# X_train[:]=scaler.fit_transform(X_train)\n",
    "# X_test[:]=scaler.transform(X_test)\n",
    "# X_train\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler=StandardScaler()\n",
    "# X_train[:]=scaler.fit_transform(X_train)\n",
    "# X_test[:]=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# corr=X_train.corr()\n",
    "# corr=corr.where(abs(corr)>0.9)\n",
    "# count = 0\n",
    "# corr_fea = []\n",
    "\n",
    "# for i in corr.columns:\n",
    "#     for j in corr.columns:\n",
    "#         if abs(corr[i][j])>0.9 and i!=j:\n",
    "#             if i not in corr_fea:\n",
    "#                 count+=1\n",
    "#                 corr_fea.append(i)\n",
    "\n",
    "#             if j not in corr_fea:\n",
    "#                 count+=1\n",
    "#                 corr_fea.append(j)\n",
    "\n",
    "# count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def is_related(pair1, pair2):\n",
    "#     if (pair1[0] in pair2 or pair1[1] in pair2) and pair1!=pair2 and not (pair1[0]==pair2[1] and pair1[1]==pair2[0]):\n",
    "#         return True\n",
    "#     return False\n",
    "\n",
    "# def add_relation(corr_fea):\n",
    "#     for i in range(len(corr_fea)):\n",
    "#         for j in range(i,len(corr_fea)):\n",
    "#             if i!=j:\n",
    "#                 if is_related(corr_fea[i],corr_fea[j]):\n",
    "#                     fea1=tuple(set(corr_fea[i])-set(corr_fea[j]))\n",
    "#                     fea2=tuple(set(corr_fea[j])-set(corr_fea[i]))\n",
    "#                     fea=fea1+fea2\n",
    "#                     if fea not in corr_fea and rev(fea) not in corr_fea:\n",
    "#                         corr_fea.append((fea1+fea2))\n",
    "\n",
    "# def rev(fea):\n",
    "#     f1=fea[0]\n",
    "#     f2=fea[1]\n",
    "\n",
    "#     return (f2,f1)\n",
    "\n",
    "# corr=X_train.corr()\n",
    "# corr=corr.where(abs(corr)>0.9)\n",
    "# count=0\n",
    "# corr_fea=[]\n",
    "# for i in corr.columns:\n",
    "#     for j in corr.columns:\n",
    "#         if i!=j and abs(corr[i][j])>0.9 and ((i,j) not in corr_fea) and ((j,i) not in corr_fea):\n",
    "#             count+=1\n",
    "#             corr_fea.append((i,j))\n",
    "#             add_relation(corr_fea)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.combine import SMOTETomek\n",
    "\n",
    "# smote=SMOTETomek()\n",
    "\n",
    "# X_train,y_train=smote.fit_resample(X_train,y=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "918 fits failed out of a total of 3000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "918 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\imblearn\\pipeline.py\", line 281, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params)\n",
      "  File \"d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 467, in fit\n",
      "    for i, t in enumerate(trees)\n",
      "  File \"d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\joblib\\parallel.py\", line 289, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\joblib\\parallel.py\", line 289, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 942, in fit\n",
      "    X_idx_sorted=X_idx_sorted,\n",
      "  File \"d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 308, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Anaconda\\envs\\mle_tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.1711501  0.22460317 0.22222222 0.26634181 0.17592593        nan\n",
      " 0.14862915        nan 0.14820082 0.28091908 0.21548822 0.25589226\n",
      " 0.25857594        nan 0.2983803         nan 0.05120773        nan\n",
      " 0.08928571        nan 0.24179949 0.15439757 0.3034188         nan\n",
      "        nan 0.14165464        nan        nan        nan 0.32006275\n",
      "        nan 0.27813699 0.22100947 0.13929896 0.16736737        nan\n",
      " 0.28023642 0.18214286 0.1503068  0.125      0.22621083 0.31041614\n",
      " 0.25022385 0.23831909 0.27755286 0.20366264 0.19044814 0.20935854\n",
      " 0.28588589        nan 0.09993675 0.17733523 0.27893352 0.06127451\n",
      " 0.14074825 0.20071155 0.15119665 0.24758138 0.21231546        nan\n",
      " 0.21367521        nan 0.21866152 0.30958165        nan 0.08541242\n",
      "        nan        nan 0.26106804 0.07150538 0.17693122 0.24843305\n",
      "        nan        nan 0.23621349 0.19188596        nan 0.13903743\n",
      " 0.27395594 0.18080808 0.28349945        nan 0.08567821        nan\n",
      "        nan 0.19140147 0.2771164  0.09485957        nan 0.25408163\n",
      "        nan 0.21593704        nan 0.12222222 0.18341014        nan\n",
      " 0.23493013 0.27302195 0.25079365        nan        nan        nan\n",
      "        nan 0.25168284 0.1078149         nan 0.08095238 0.16990352\n",
      "        nan 0.14925842 0.0475            nan 0.09166667 0.10353535\n",
      "        nan        nan 0.27454174        nan 0.13049413 0.24608248\n",
      " 0.0997151         nan        nan 0.1702381  0.1912733  0.27197507\n",
      " 0.18319328        nan 0.14720435 0.26622777 0.16033787 0.3389807\n",
      " 0.26364764 0.17597827        nan 0.24241384 0.08013136        nan\n",
      " 0.31170239 0.34158011 0.20876564        nan 0.3130965  0.22227772\n",
      " 0.20009036 0.36763237 0.20721248 0.24137032 0.1969697         nan\n",
      " 0.04040404        nan 0.04691358        nan 0.11448413 0.36046338\n",
      " 0.24503507 0.13742785        nan 0.28770914        nan 0.2315649\n",
      "        nan 0.18617512 0.25422531        nan 0.19144144 0.10788643\n",
      " 0.28789229 0.06451613 0.14146825        nan        nan 0.16246158\n",
      " 0.08592873 0.10833333        nan 0.22922878        nan 0.11373874\n",
      "        nan 0.13405483 0.1587963  0.11447401 0.15766864 0.09569378\n",
      " 0.25867417        nan 0.22172246        nan        nan        nan\n",
      "        nan 0.30193678 0.26510667 0.21523116 0.23414918 0.16699346\n",
      "        nan 0.02298851 0.08407225 0.1557322  0.20741042 0.22651727\n",
      " 0.23492063 0.08278388 0.2829414         nan 0.15763305 0.22336143\n",
      "        nan 0.21891911 0.11578245 0.24222684        nan 0.25470383\n",
      " 0.19058029 0.21310966        nan 0.17873983 0.24867725 0.21996779\n",
      "        nan        nan 0.16733902        nan        nan 0.16923077\n",
      " 0.13921569 0.15646663 0.25615367        nan 0.24514515 0.16287752\n",
      "        nan        nan 0.23477048 0.27464387 0.30093906 0.26012376\n",
      " 0.26066589 0.21929917 0.17615065        nan        nan        nan\n",
      "        nan 0.1980057  0.24037884 0.32850959        nan        nan\n",
      " 0.19733534 0.27191995 0.16053922        nan 0.2331333         nan\n",
      "        nan        nan 0.13515782 0.15229215        nan        nan\n",
      " 0.04103535        nan 0.19201907 0.18614551 0.16779017 0.37967125\n",
      "        nan        nan 0.30311424 0.24361208 0.13791816 0.25616755\n",
      "        nan 0.21623094 0.23715144        nan 0.22920481 0.30925688\n",
      "        nan 0.2150808  0.17994987 0.30230704        nan 0.22276822\n",
      " 0.19724311        nan 0.04166667        nan        nan 0.29358603\n",
      " 0.32205387        nan 0.10163674 0.19442613 0.10416667        nan\n",
      " 0.25917393 0.26772927 0.14446094        nan 0.16423663        nan\n",
      " 0.21802326 0.14412095        nan 0.24162022        nan 0.26505665\n",
      " 0.11063218 0.29868875 0.31420645 0.32127385 0.20440687        nan\n",
      " 0.27844396 0.16645446 0.20296767        nan        nan 0.27556018\n",
      " 0.17889521        nan 0.2542315  0.14128287 0.25079365 0.31096866\n",
      "        nan 0.24969773 0.38053872        nan        nan        nan\n",
      " 0.19549663 0.26565027        nan 0.18297005 0.10880042 0.24170512\n",
      " 0.33103481 0.23646922 0.30729433 0.24760425 0.13261649 0.19560811\n",
      " 0.30952381 0.2379386  0.08263305        nan 0.25127465 0.31022883\n",
      " 0.21866771 0.11659452 0.22002442 0.19505984        nan 0.19454682\n",
      "        nan 0.08898776 0.2393514  0.19215686        nan 0.26716792\n",
      " 0.08928571 0.27975818 0.12395606 0.27203907        nan        nan\n",
      " 0.3599256  0.20643939 0.21272716 0.15941558 0.21866152 0.27327327\n",
      " 0.23093161 0.28429858 0.15229215 0.13564214        nan 0.16090863\n",
      "        nan 0.3348916         nan        nan 0.23216765        nan\n",
      " 0.32301342 0.33977011        nan        nan 0.09382716        nan\n",
      " 0.25296638 0.24465595        nan 0.15595238        nan 0.23787879\n",
      " 0.08683473 0.30980861 0.19328419 0.18747823        nan 0.25819736\n",
      " 0.26611587        nan 0.32047119 0.201365   0.28287077 0.15941877\n",
      "        nan 0.08454106 0.25088946        nan 0.2840219  0.14093137\n",
      " 0.08683473        nan 0.19200499 0.2076449  0.19718013 0.23359788\n",
      "        nan 0.30981169        nan 0.28570853 0.0471464  0.13746662\n",
      " 0.34558824 0.23598185 0.12961344 0.1087781  0.21779449 0.24296137\n",
      "        nan 0.14981809 0.18407418        nan 0.21288515 0.17692482\n",
      " 0.14550265 0.07160494        nan        nan        nan 0.2959964\n",
      " 0.08624709        nan 0.15540541 0.16172757 0.15473058        nan\n",
      "        nan 0.03921569        nan 0.15612076        nan 0.12305556\n",
      " 0.17211329 0.12045183        nan        nan        nan        nan\n",
      "        nan 0.19207158 0.10529471 0.24535604 0.11674347 0.37057057\n",
      "        nan        nan        nan 0.21963508 0.20186312 0.32693494\n",
      " 0.25531915 0.10596993        nan        nan 0.19337607 0.18335983\n",
      "        nan        nan 0.20461872        nan 0.22181299 0.17811318\n",
      " 0.13049413 0.1990562  0.03921569        nan        nan 0.32992539\n",
      " 0.26352506 0.31494431 0.24834656 0.24328419 0.24962406        nan\n",
      " 0.22033222 0.28059204 0.232493   0.147879   0.16710969        nan\n",
      "        nan        nan 0.13103384        nan        nan 0.30796335\n",
      "        nan 0.17945845        nan 0.29274029 0.24915209 0.24929215\n",
      " 0.24035464        nan        nan 0.19424951 0.35122655 0.02222222\n",
      " 0.14055765        nan 0.18917625 0.28096764        nan 0.20655133\n",
      "        nan        nan 0.1577342  0.28430049 0.24469721 0.26853887\n",
      " 0.19212316 0.23991254        nan        nan 0.28983356 0.25082733\n",
      " 0.31322455 0.2248538  0.23262548 0.34933475 0.10557763 0.14553753\n",
      "        nan 0.14579876 0.13873147 0.32534649 0.14892788 0.25282865\n",
      " 0.25184345 0.33064545        nan 0.10270196 0.23432245        nan\n",
      "        nan 0.17384766        nan        nan        nan 0.30625486\n",
      " 0.21771772 0.16341066        nan        nan 0.26534938        nan\n",
      " 0.20164365        nan 0.25701754 0.10568182 0.10235359        nan\n",
      " 0.1468615         nan 0.15257937 0.32341034 0.1791958  0.30775336\n",
      "        nan 0.31537825 0.16895428        nan 0.31651652 0.1588551\n",
      " 0.25111189 0.11350346 0.11309524 0.25220675 0.13055556 0.26311899\n",
      "        nan 0.14590348        nan        nan        nan        nan\n",
      "        nan 0.13174603 0.08995776        nan 0.28781291 0.15103622\n",
      "        nan 0.19200153        nan 0.30578921 0.20464651 0.26593454\n",
      " 0.09948157 0.31558442 0.32251082        nan 0.15810811 0.20942982\n",
      " 0.1743448  0.17808701 0.28296351 0.24035464 0.1130786  0.24087549\n",
      " 0.2424812  0.23646724 0.20086149 0.1        0.15001365 0.21625158\n",
      "        nan 0.2080568  0.24209664 0.14388121 0.06186869 0.1547619\n",
      " 0.22317922 0.33647402 0.21532999 0.18730159 0.31231231 0.22067888\n",
      " 0.26916462        nan        nan 0.16700473 0.21734893 0.10652338\n",
      "        nan 0.0625     0.28034188        nan 0.11767544 0.23809524\n",
      "        nan 0.16560145        nan        nan 0.11525041 0.25518542\n",
      " 0.1746633         nan 0.1935142  0.1132716  0.16436252 0.06604507\n",
      " 0.2546081  0.22789433 0.25950989 0.16945517 0.17566138 0.2511477\n",
      "        nan 0.23127413 0.12303709 0.20790021 0.21508552 0.29128466\n",
      " 0.30352304 0.20271771 0.17724868        nan        nan        nan\n",
      " 0.1751948  0.06384409 0.26190476 0.23015873        nan        nan\n",
      "        nan        nan 0.21810382 0.13597884        nan 0.22296494\n",
      " 0.22812178        nan 0.24781488        nan 0.1898183         nan\n",
      "        nan        nan 0.29006734 0.08207071        nan 0.18170426\n",
      "        nan        nan        nan 0.31804511        nan 0.25166098\n",
      " 0.22940948 0.26962388        nan 0.27781382 0.24822383        nan\n",
      " 0.18119081 0.24868026 0.17942733 0.14415396 0.18820581        nan\n",
      "        nan        nan 0.17843137        nan 0.22428941        nan\n",
      "        nan 0.12968658        nan 0.27404408 0.14830586 0.25460622\n",
      " 0.29138443        nan        nan 0.08903357 0.22683402        nan\n",
      " 0.17210961 0.20793651        nan        nan        nan 0.17068066\n",
      " 0.25667528        nan 0.06451613 0.26452676 0.23261129 0.26432881\n",
      " 0.22804103 0.18965517 0.23414918 0.15119396 0.15115995 0.11870923\n",
      " 0.25643347        nan        nan 0.19675926 0.12766684 0.10834011\n",
      " 0.16257153 0.14356292 0.21647851 0.31686047        nan        nan\n",
      " 0.25235344 0.21599238        nan 0.16589424 0.17162698 0.09167992\n",
      " 0.1995614  0.13637566 0.20143647 0.11897759 0.16176471 0.15057135\n",
      " 0.16336638 0.07965686 0.13869048 0.26300125 0.29505582 0.14954052\n",
      " 0.25811966 0.16865079        nan 0.23629344        nan 0.21212121\n",
      "        nan 0.13657407        nan 0.0650954  0.18296586 0.21946533\n",
      " 0.26327947 0.26656068        nan        nan        nan 0.17535014\n",
      "        nan 0.15867542 0.16532999 0.28929117        nan        nan\n",
      " 0.26852951 0.12298851 0.23710708 0.10509804 0.18926907 0.24572847\n",
      " 0.14726709        nan 0.15572716        nan 0.09104938 0.02222222\n",
      " 0.24421195 0.18550115 0.36806202 0.21014118 0.27401722        nan\n",
      "        nan        nan 0.25567939 0.08467742        nan        nan\n",
      "        nan 0.1737782  0.30222382 0.11442337 0.35382605 0.39827371\n",
      " 0.08400538 0.21896622 0.14659197 0.19183442 0.2043956         nan\n",
      " 0.16534181 0.17909434 0.18145363 0.06682028        nan        nan\n",
      " 0.11616162 0.02020202 0.32949706 0.20464047 0.16135779        nan\n",
      "        nan 0.04521073 0.11596639 0.1453149  0.22241087 0.24914785\n",
      " 0.09085419 0.20566908 0.25377005 0.08755044 0.15484336        nan\n",
      " 0.21112238 0.13735676 0.2276066  0.27591463 0.29215229        nan\n",
      " 0.17072511 0.22226662 0.18951613        nan 0.16514597 0.18215812\n",
      " 0.09104938 0.02083333        nan 0.33886225 0.15985061        nan\n",
      "        nan 0.27777778        nan 0.26190476 0.29194529 0.09794545\n",
      " 0.20850808        nan 0.24499642 0.09666878        nan 0.30366133\n",
      " 0.14920635 0.12754065 0.27519249 0.23589744 0.11774892 0.21216216\n",
      " 0.27280558        nan        nan        nan 0.21808279 0.17936508\n",
      "        nan 0.25727197 0.29969377 0.20524179        nan 0.22995452\n",
      " 0.14870497 0.04619673 0.2316941  0.18029718 0.39634644 0.28544974\n",
      "        nan 0.2140056  0.15618551 0.25154799        nan        nan\n",
      " 0.26943012 0.10238773 0.24112979 0.14431373 0.10311987 0.08630952\n",
      " 0.17604618 0.13435243 0.2517094  0.18479054        nan 0.17283951\n",
      " 0.16949417 0.25066324 0.1885134  0.21694319 0.17330164 0.22907268\n",
      "        nan 0.34638943 0.22286572 0.17699768        nan        nan\n",
      " 0.17701034 0.23135965 0.0964783         nan 0.3486173         nan\n",
      " 0.15951178        nan 0.2037037  0.32425469        nan 0.15237447\n",
      "        nan        nan 0.23100183 0.12445055        nan 0.22578348\n",
      " 0.13962781 0.06730769        nan 0.16991688 0.06707071        nan\n",
      "        nan 0.15532307 0.19479479 0.21299145        nan 0.25917714\n",
      " 0.1878225  0.21615245        nan        nan]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.398):\n",
      "{'rf__n_estimators': 100, 'rf__max_features': 30, 'rf__max_depth': 10, 'rf__class_weight': 'balanced', 'resample__smote': SMOTE(sampling_strategy=1.0), 'pca__n_components': 30, 'imputeOutlier__n_neighbors': 200, 'imputeNull__n_neighbors': 100, 'imputeMissing__n_neighbors': 200}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84        60\n",
      "           1       0.40      0.21      0.28        19\n",
      "\n",
      "    accuracy                           0.73        79\n",
      "   macro avg       0.59      0.56      0.56        79\n",
      "weighted avg       0.69      0.73      0.70        79\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[54,  6],\n",
       "       [15,  4]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks \n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "para={'imputeNull__n_neighbors':[50,100,200],\n",
    "    'imputeMissing__n_neighbors':[50,100,200],\n",
    "    'imputeOutlier__n_neighbors':[50,100,200],\n",
    "    'pca__n_components':[30,40,50,60,70],\n",
    "    'resample__smote':[SMOTE(sampling_strategy=0.6),SMOTE(sampling_strategy=0.8),\n",
    "                       SMOTE(sampling_strategy=1.0)],\n",
    "    'rf__class_weight':['balanced'],\n",
    "    'rf__max_depth':[10,20,30,40],\n",
    "    'rf__max_features':[15,20,30,50,100],\n",
    "    'rf__n_estimators':[100,200,300]\n",
    "}\n",
    "\n",
    "pipe=Pipeline([('drop',columnDropperTransformer(['ID'])),\n",
    "    ('imputeNull',KNNImputer(missing_values=np.nan,n_neighbors=200)),\n",
    "    ('imputeMissing',KNNImputer(missing_values=np.float64(999),n_neighbors=200)),\n",
    "    ('outlier',outlierHandlingWithDev()),\n",
    "    ('imputeOutlier',KNNImputer(missing_values=np.float64(999),n_neighbors=200)),\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('pca',PCA(n_components=60)),\n",
    "    ('resample',SMOTETomek(smote=SMOTE(sampling_strategy=1.0),tomek=TomekLinks())),\n",
    "    ('rf',RandomForestClassifier())\n",
    "])\n",
    "\n",
    "grid=RandomizedSearchCV(pipe,n_iter=1000,param_distributions=para,n_jobs=-1,cv=KFold(n_splits=3), scoring='f1')\n",
    "\n",
    "grid.fit(X_train,y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "print(classification_report(y_test,pipe.predict(X_test)))\n",
    "confusion_matrix(y_test,pipe.predict(X_test))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.390):\n",
      "{'imputeMissing__n_neighbors': 100, 'imputeNull__n_neighbors': 50, 'imputeOutlier__n_neighbors': 200, 'pca__n_components': 30, 'resample__smote': SMOTE(sampling_strategy=1.0), 'rf__class_weight': 'balanced', 'rf__max_depth': 40, 'rf__max_features': 15, 'rf__n_estimators': 200}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87        60\n",
      "           1       0.62      0.26      0.37        19\n",
      "\n",
      "    accuracy                           0.78        79\n",
      "   macro avg       0.71      0.61      0.62        79\n",
      "weighted avg       0.76      0.78      0.75        79\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[57,  3],\n",
       "       [14,  5]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks \n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "para={'imputeNull__n_neighbors':[50,100],\n",
    "    'imputeMissing__n_neighbors':[100,200],\n",
    "    'imputeOutlier__n_neighbors':[100,200],\n",
    "    'pca__n_components':[30,40],\n",
    "    'resample__smote':[\n",
    "                       SMOTE(sampling_strategy=1.0)],\n",
    "    'rf__class_weight':['balanced'],\n",
    "    'rf__max_depth':[30,40],\n",
    "    'rf__max_features':[10,15],\n",
    "    'rf__n_estimators':[100,200]\n",
    "}\n",
    "\n",
    "pipe=Pipeline([('drop',columnDropperTransformer(['ID'])),\n",
    "    ('imputeNull',KNNImputer(missing_values=np.nan,n_neighbors=200)),\n",
    "    ('imputeMissing',KNNImputer(missing_values=np.float64(999),n_neighbors=200)),\n",
    "    ('outlier',outlierHandlingWithDev()),\n",
    "    ('imputeOutlier',KNNImputer(missing_values=np.float64(999),n_neighbors=200)),\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('pca',PCA(n_components=60)),\n",
    "    ('resample',SMOTETomek(smote=SMOTE(sampling_strategy=1.0),tomek=TomekLinks())),\n",
    "    ('rf',RandomForestClassifier())\n",
    "])\n",
    "\n",
    "grid=GridSearchCV(pipe,param_grid=para,n_jobs=-1,cv=KFold(n_splits=3), scoring='f1')\n",
    "\n",
    "grid.fit(X_train,y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "print(classification_report(y_test,pipe.predict(X_test)))\n",
    "confusion_matrix(y_test,pipe.predict(X_test))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in grid.get_params().keys():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5700\\3135758680.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.04\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mscore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "clf=MLPClassifier(hidden_layer_sizes=(20,30),activation=\"relu\",alpha=0.04,max_iter=1000,batch_size=20,random_state=2,early_stopping=True,shuffle=True)\n",
    "score=cross_val_score(clf,X_train,y_train,cv=KFold(n_splits=5,shuffle=True,random_state=2))\n",
    "print(score.mean())\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "print(classification_report(y_test,clf.predict(X_test)))\n",
    "confusion_matrix(y_test,clf.predict(X_test))\n",
    "# confusion_matrix(y_train,clf.predict(X_train))\n",
    "# seq.fit(X_train,y_train)\n",
    "# X_train=seq.transform(X_train)\n",
    "# X_test=seq.transform(X_test)\n",
    "# clf.fit(X_train,y_train)\n",
    "# print(classification_report(y_test,clf.predict(X_test)))\n",
    "# confusion_matrix(y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.tree import  DecisionTreeClassifier\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.feature_selection import SequentialFeatureSelector\n",
    "# clf=DecisionTreeClassifier(class_weight='balanced',random_state=global_seed)\n",
    "# # clf.fit(X_train,y_train)\n",
    "# # clf.predict(X_test)\n",
    "#\n",
    "# clf.fit(X_train,y_train)\n",
    "#\n",
    "# print(classification_report(y_test,clf.predict(X_test)))\n",
    "# confusion_matrix(y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf=MLPClassifier(hidden_layer_sizes=(23,30),alpha=0.1,activation=\"relu\",max_iter=500,batch_size=20)\n",
    "# cross_val_score(clf,X_train,y_train,cv=3)\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "# sfs=SequentialFeatureSelector(clf,n_features_to_select=\"auto\")\n",
    "#\n",
    "clf.fit(X_train,y_train)\n",
    "print(classification_report(y_test,clf.predict(X_test)))\n",
    "confusion_matrix(y_test,clf.predict(X_test))\n",
    "confusion_matrix(y_train,clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf=SVC(kernel=\"poly\",random_state=global_seed,degree=2)\n",
    "para={'kernel':[\"poly\",\"linear\",\"rbf\"],'degree':[1,2,3,4,5],'class_weight':[{0:1.,1:2.},{0:1.,1:20.},None]}\n",
    "cv=GridSearchCV(clf,param_grid=para,cv=KFold(n_splits=5,random_state=global_seed,shuffle=True))\n",
    "cv.fit(X_train,y_train)\n",
    "print(cv.best_params_)\n",
    "print(confusion_matrix(cv.predict(X_test),y_test))\n",
    "print(classification_report(cv.predict(X_test),y_test))\n",
    "\n",
    "# clf.fit(X_train,y_train)\n",
    "confusion_matrix(y_true=y_train,y_pred=cv.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf=KNeighborsClassifier(weights=\"distance\")\n",
    "para={'n_neighbors':[2,3,4,5,6,7,8,9,10,12,15,19]}\n",
    "cv=GridSearchCV(clf,param_grid=para,cv=KFold(n_splits=5,random_state=global_seed,shuffle=True))\n",
    "cv.fit(X_train,y_train)\n",
    "print(confusion_matrix(cv.predict(X_test),y_test))\n",
    "\n",
    "# cv.estimator.fit(X_train,y_train)\n",
    "# confusion_matrix(y_true=y_test,y_pred=clf.predict(X_test))\n",
    "print(classification_report(y_test,cv.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.utils import class_weight\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# model=keras.Sequential()\n",
    "# model.add(keras.layers.Dense(20,input_dim=len(X_train[0]),activation=\"relu\"))\n",
    "# model.add(keras.layers.Dense(10,activation=\"relu\"))\n",
    "# model.add(keras.layers.Dense(1,activation=\"sigmoid\"))\n",
    "# model.summary()\n",
    "#\n",
    "# model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[tf.keras.metrics.Precision(),\"accuracy\"])\n",
    "# # model.save_weights('model.h5')\n",
    "# # model.load_weights('model.h5')\n",
    "# history=model.fit(X_train,np.array(y_train),epochs=20,validation_data=(X_test,np.array(y_test)),batch_size=20)\n",
    "# y_pred=model.predict(X_test)\n",
    "# loss,precision,acc=model.evaluate(X_test,np.array(y_test),verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mle_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de28e1e25f48b68b9638a29c8142fb7816a4ec90feebba1cd15c63ff7df4d74f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
