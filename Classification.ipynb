{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "            ID  pCR (outcome)  RelapseFreeSurvival (outcome)   Age  ER  PgR  \\\n0    TRG002174              1                     144.000000  41.0   0  0.0   \n1    TRG002178              0                     142.000000  39.0   1  1.0   \n2    TRG002204              1                     135.000000  31.0   0  0.0   \n3    TRG002206              0                      12.000000  35.0   0  0.0   \n4    TRG002210              0                     109.000000  61.0   1  0.0   \n..         ...            ...                            ...   ...  ..  ...   \n394  TRG002954              0                      49.250000  34.3   0  0.0   \n395  TRG002955              1                      49.250000  46.1   0  0.0   \n396  TRG002958              0                      48.500000  53.3   0  0.0   \n397  TRG002961              0                      47.500000  68.8   1  0.0   \n398  TRG002962              0                      46.916667  46.0   1  0.0   \n\n     HER2  TrippleNegative  ChemoGrade  Proliferation  ...  \\\n0     0.0              1.0           3              3  ...   \n1     0.0              0.0           3              3  ...   \n2     0.0              1.0           2              1  ...   \n3     0.0              1.0           3              3  ...   \n4     0.0              0.0           2              1  ...   \n..    ...              ...         ...            ...  ...   \n394   0.0              1.0           3              3  ...   \n395   0.0              1.0           3              3  ...   \n396   0.0              1.0           2              1  ...   \n397   0.0              0.0           3              3  ...   \n398   0.0              0.0           2              1  ...   \n\n     original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n0                                         0.517172   \n1                                         0.444391   \n2                                         0.534549   \n3                                         0.506185   \n4                                         0.462282   \n..                                             ...   \n394                                       0.418382   \n395                                       0.439568   \n396                                       0.527779   \n397                                       0.313693   \n398                                       0.670229   \n\n     original_glszm_SmallAreaLowGrayLevelEmphasis  original_glszm_ZoneEntropy  \\\n0                                        0.375126                    3.325332   \n1                                        0.444391                    3.032144   \n2                                        0.534549                    2.485848   \n3                                        0.506185                    2.606255   \n4                                        0.462282                    2.809279   \n..                                            ...                         ...   \n394                                      0.418382                    2.995603   \n395                                      0.439568                    3.056046   \n396                                      0.527778                    1.500000   \n397                                      0.313693                    3.573557   \n398                                      0.670229                    1.857045   \n\n     original_glszm_ZonePercentage  original_glszm_ZoneVariance  \\\n0                         0.002314                 3.880772e+06   \n1                         0.005612                 2.372010e+06   \n2                         0.006752                 1.540027e+06   \n3                         0.003755                 6.936741e+06   \n4                         0.006521                 1.265399e+06   \n..                             ...                          ...   \n394                       0.004243                 1.005061e+06   \n395                       0.001339                 1.671271e+07   \n396                       0.003728                 2.132007e+05   \n397                       0.001112                 2.008034e+07   \n398                       0.006706                 5.609262e+05   \n\n     original_ngtdm_Busyness  original_ngtdm_Coarseness  \\\n0                 473.464852                   0.000768   \n1                  59.459710                   0.004383   \n2                  33.935384                   0.007584   \n3                  46.859265                   0.005424   \n4                  39.621023                   0.006585   \n..                       ...                        ...   \n394               156.627179                   0.002228   \n395                79.989003                   0.003282   \n396                 0.996746                   0.252582   \n397               204.864200                   0.001372   \n398                 9.609163                   0.026591   \n\n     original_ngtdm_Complexity  original_ngtdm_Contrast  \\\n0                     0.182615                 0.030508   \n1                     0.032012                 0.001006   \n2                     0.024062                 0.000529   \n3                     0.013707                 0.000178   \n4                     0.034148                 0.001083   \n..                         ...                      ...   \n394                   0.136015                 0.022148   \n395                   0.024716                 0.000812   \n396                   0.007380                 0.000037   \n397                   0.054063                 0.003697   \n398                   0.018682                 0.000311   \n\n     original_ngtdm_Strength  \n0                   0.000758  \n1                   0.003685  \n2                   0.006447  \n3                   0.004543  \n4                   0.005626  \n..                       ...  \n394                 0.002098  \n395                 0.003078  \n396                 0.231059  \n397                 0.001368  \n398                 0.022676  \n\n[394 rows x 120 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>pCR (outcome)</th>\n      <th>RelapseFreeSurvival (outcome)</th>\n      <th>Age</th>\n      <th>ER</th>\n      <th>PgR</th>\n      <th>HER2</th>\n      <th>TrippleNegative</th>\n      <th>ChemoGrade</th>\n      <th>Proliferation</th>\n      <th>...</th>\n      <th>original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n      <th>original_glszm_SmallAreaLowGrayLevelEmphasis</th>\n      <th>original_glszm_ZoneEntropy</th>\n      <th>original_glszm_ZonePercentage</th>\n      <th>original_glszm_ZoneVariance</th>\n      <th>original_ngtdm_Busyness</th>\n      <th>original_ngtdm_Coarseness</th>\n      <th>original_ngtdm_Complexity</th>\n      <th>original_ngtdm_Contrast</th>\n      <th>original_ngtdm_Strength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRG002174</td>\n      <td>1</td>\n      <td>144.000000</td>\n      <td>41.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.517172</td>\n      <td>0.375126</td>\n      <td>3.325332</td>\n      <td>0.002314</td>\n      <td>3.880772e+06</td>\n      <td>473.464852</td>\n      <td>0.000768</td>\n      <td>0.182615</td>\n      <td>0.030508</td>\n      <td>0.000758</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRG002178</td>\n      <td>0</td>\n      <td>142.000000</td>\n      <td>39.0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.444391</td>\n      <td>0.444391</td>\n      <td>3.032144</td>\n      <td>0.005612</td>\n      <td>2.372010e+06</td>\n      <td>59.459710</td>\n      <td>0.004383</td>\n      <td>0.032012</td>\n      <td>0.001006</td>\n      <td>0.003685</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRG002204</td>\n      <td>1</td>\n      <td>135.000000</td>\n      <td>31.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.534549</td>\n      <td>0.534549</td>\n      <td>2.485848</td>\n      <td>0.006752</td>\n      <td>1.540027e+06</td>\n      <td>33.935384</td>\n      <td>0.007584</td>\n      <td>0.024062</td>\n      <td>0.000529</td>\n      <td>0.006447</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRG002206</td>\n      <td>0</td>\n      <td>12.000000</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.506185</td>\n      <td>0.506185</td>\n      <td>2.606255</td>\n      <td>0.003755</td>\n      <td>6.936741e+06</td>\n      <td>46.859265</td>\n      <td>0.005424</td>\n      <td>0.013707</td>\n      <td>0.000178</td>\n      <td>0.004543</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRG002210</td>\n      <td>0</td>\n      <td>109.000000</td>\n      <td>61.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.462282</td>\n      <td>0.462282</td>\n      <td>2.809279</td>\n      <td>0.006521</td>\n      <td>1.265399e+06</td>\n      <td>39.621023</td>\n      <td>0.006585</td>\n      <td>0.034148</td>\n      <td>0.001083</td>\n      <td>0.005626</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>TRG002954</td>\n      <td>0</td>\n      <td>49.250000</td>\n      <td>34.3</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.418382</td>\n      <td>0.418382</td>\n      <td>2.995603</td>\n      <td>0.004243</td>\n      <td>1.005061e+06</td>\n      <td>156.627179</td>\n      <td>0.002228</td>\n      <td>0.136015</td>\n      <td>0.022148</td>\n      <td>0.002098</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>TRG002955</td>\n      <td>1</td>\n      <td>49.250000</td>\n      <td>46.1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.439568</td>\n      <td>0.439568</td>\n      <td>3.056046</td>\n      <td>0.001339</td>\n      <td>1.671271e+07</td>\n      <td>79.989003</td>\n      <td>0.003282</td>\n      <td>0.024716</td>\n      <td>0.000812</td>\n      <td>0.003078</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>TRG002958</td>\n      <td>0</td>\n      <td>48.500000</td>\n      <td>53.3</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.527779</td>\n      <td>0.527778</td>\n      <td>1.500000</td>\n      <td>0.003728</td>\n      <td>2.132007e+05</td>\n      <td>0.996746</td>\n      <td>0.252582</td>\n      <td>0.007380</td>\n      <td>0.000037</td>\n      <td>0.231059</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>TRG002961</td>\n      <td>0</td>\n      <td>47.500000</td>\n      <td>68.8</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.313693</td>\n      <td>0.313693</td>\n      <td>3.573557</td>\n      <td>0.001112</td>\n      <td>2.008034e+07</td>\n      <td>204.864200</td>\n      <td>0.001372</td>\n      <td>0.054063</td>\n      <td>0.003697</td>\n      <td>0.001368</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>TRG002962</td>\n      <td>0</td>\n      <td>46.916667</td>\n      <td>46.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.670229</td>\n      <td>0.670229</td>\n      <td>1.857045</td>\n      <td>0.006706</td>\n      <td>5.609262e+05</td>\n      <td>9.609163</td>\n      <td>0.026591</td>\n      <td>0.018682</td>\n      <td>0.000311</td>\n      <td>0.022676</td>\n    </tr>\n  </tbody>\n</table>\n<p>394 rows × 120 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset=pd.read_excel(\"C:/Users/10253/Desktop/ML-CW-2/Data/trainDataset.xls\")\n",
    "dataset=dataset[dataset[\"pCR (outcome)\"]!=999]\n",
    "dataset.head(len(dataset)-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# from sklearn.impute import  SimpleImputer\n",
    "# imp=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "# names=dataset.columns.drop('ID')\n",
    "# a=imp.fit_transform(dataset.drop('ID',axis=1))\n",
    "# imp=SimpleImputer(missing_values=999,strategy='mean')\n",
    "# a=imp.fit_transform(a)\n",
    "# df=pd.DataFrame(a,columns=\n",
    "#                 names)\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Removing duplicate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset.drop_duplicates(inplace=True) #because with 119 features, it is unlikely that exact same data happens in real world, it is useless for training and testing; hence remove it before dataset split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0    299\n1     96\nName: pCR (outcome), dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['pCR (outcome)'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "y=dataset['pCR (outcome)']\n",
    "X=dataset.drop(['pCR (outcome)'],axis=1)\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,stratify=y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### drop columns that are not applicable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class columnDropperTransformer(): #https://stackoverflow.com/questions/68402691/adding-dropping-column-instance-into-a-pipeline\n",
    "    def __init__(self,columns):\n",
    "        self.columns=columns\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "        return X.drop(self.columns,axis=1)\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return X.drop(self.columns,axis=1)\n",
    "\n",
    "dropper = columnDropperTransformer(['ID'])\n",
    "X_train=dropper.fit_transform(X_train)\n",
    "\n",
    "X_test=dropper.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### missing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "ID                               0\npCR (outcome)                    0\nRelapseFreeSurvival (outcome)    0\nAge                              0\nER                               0\n                                ..\noriginal_ngtdm_Busyness          0\noriginal_ngtdm_Coarseness        0\noriginal_ngtdm_Complexity        0\noriginal_ngtdm_Contrast          0\noriginal_ngtdm_Strength          0\nLength: 120, dtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "names=X_train.columns\n",
    "\n",
    "imp=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "# X_train[:]=imp.fit_transform(X_train)\n",
    "# X_test[:]=imp.transform(X_test)\n",
    "X_train=imp.fit_transform(X_train)\n",
    "X_test=imp.transform(X_test)\n",
    "\n",
    "imp.missing_values=np.float64(999)\n",
    "# X_train[:]=imp.fit_transform(X_train)\n",
    "# X_test[:]=imp.transform(X_test)\n",
    "X_train=imp.fit_transform(X_train)\n",
    "X_test=imp.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Removing outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# because use LocalOutlierFactor may lose useful information becuase whenever there is an outlier in any features of the sample, the sample will be detected as outlier sample and all its information will be set to 999\n",
    "# therefore, use other method\n",
    "\n",
    "class outlierHandlingWithDev():\n",
    "    def fit(self,X,y=None):\n",
    "        self.mean=np.zeros(len(X[0]))\n",
    "        self.std=np.zeros(len(X[0]))\n",
    "        for i in range(len(X[0])):\n",
    "            self.mean[i]=X[:,i].mean()\n",
    "            self.std[i]=X[:,i].std()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "        for i in range(len(X)):\n",
    "            for j in range(len(X[i])):\n",
    "                if np.abs(X[i][j]-self.mean[j])>3*self.std[j]:\n",
    "                    X[i][j]=999\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        self.fit(X,y)\n",
    "        return self.transform(X,y)\n",
    "    # def fit(self,X,y=None):\n",
    "    #     self.mean=X.mean(axis=0)\n",
    "    #     self.std=X.std(axis=0)\n",
    "    #\n",
    "    #     return self\n",
    "    #\n",
    "    # def transform(self,X,y=None):\n",
    "    #     for i in X.columns:\n",
    "    #         for j in range(len(X)):\n",
    "    #             if abs(X[i][j]-self.mean[i])>(3*self.std[i]):\n",
    "    #                 X[i][j]=999\n",
    "    #\n",
    "    #     return X\n",
    "    #\n",
    "    # def fit_transform(self,X,y=None):\n",
    "    #     self.fit(X,y)\n",
    "    #     return self.transform(X,y)\n",
    "\n",
    "detector=outlierHandlingWithDev()\n",
    "detector.fit(X_train)\n",
    "detector.transform(X_train)\n",
    "detector.transform(X_test)\n",
    "\n",
    "X_train=imp.fit_transform(X_train)\n",
    "X_test=imp.transform(X_test)\n",
    "\n",
    "X_train=pd.DataFrame(X_train,columns=names)\n",
    "X_test=pd.DataFrame(X_test,columns=names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Binning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### resample"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote=SMOTE()\n",
    "\n",
    "X_train,y_train=smote.fit_resample(X_train,y_train)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MinMaxScaler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "     RelapseFreeSurvival (outcome)       Age        ER       PgR      HER2  \\\n0                         0.456897  0.191874  1.000000  1.000000  1.000000   \n1                         0.775862  0.325517  1.000000  1.000000  1.000000   \n2                         0.482759  0.687807  0.000000  0.000000  0.000000   \n3                         0.043103  0.150089  1.000000  0.000000  0.000000   \n4                         0.715517  0.865464  1.000000  1.000000  0.000000   \n..                             ...       ...       ...       ...       ...   \n473                       0.757716  0.308502  1.000000  1.000000  1.000000   \n474                       0.454282  0.365053  0.000000  0.000000  1.000000   \n475                       0.440622  0.358889  0.000000  0.000000  0.000000   \n476                       0.407674  0.422152  0.000000  0.000000  0.406409   \n477                       0.292951  0.428162  0.508834  0.508834  1.000000   \n\n     TrippleNegative  ChemoGrade  Proliferation  HistologyType  LNStatus  ...  \\\n0           0.000000    1.000000       0.500000            0.0  0.000000  ...   \n1           0.000000    0.500000       0.500000            0.0  1.000000  ...   \n2           1.000000    0.500000       0.000000            0.0  1.000000  ...   \n3           0.000000    1.000000       0.500000            0.0  0.000000  ...   \n4           0.000000    0.500000       0.000000            1.0  1.000000  ...   \n..               ...         ...            ...            ...       ...  ...   \n473         0.000000    1.000000       0.953039            0.0  0.906077  ...   \n474         0.000000    0.757719       0.515437            0.0  0.515437  ...   \n475         1.000000    0.500000       0.484302            0.0  0.000000  ...   \n476         0.593591    0.500000       0.296796            0.0  0.000000  ...   \n477         0.000000    0.245583       0.000000            0.0  0.491166  ...   \n\n     original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n0                                         0.651945   \n1                                         0.530456   \n2                                         0.417041   \n3                                         0.347732   \n4                                         0.558902   \n..                                             ...   \n473                                       0.091304   \n474                                       0.490071   \n475                                       0.619175   \n476                                       0.628515   \n477                                       0.200673   \n\n     original_glszm_SmallAreaLowGrayLevelEmphasis  original_glszm_ZoneEntropy  \\\n0                                        0.667335                    0.323326   \n1                                        0.542978                    0.470137   \n2                                        0.426887                    0.562781   \n3                                        0.355941                    0.570773   \n4                                        0.572096                    0.404490   \n..                                            ...                         ...   \n473                                      0.093459                    0.700720   \n474                                      0.501641                    0.494613   \n475                                      0.633792                    0.362542   \n476                                      0.643353                    0.410029   \n477                                      0.205409                    0.487895   \n\n     original_glszm_ZonePercentage  original_glszm_ZoneVariance  \\\n0                         0.279340                     0.003136   \n1                         0.677938                     0.000718   \n2                         0.054941                     0.081159   \n3                         0.187794                     0.006259   \n4                         0.041034                     0.114394   \n..                             ...                          ...   \n473                       0.243464                     0.004023   \n474                       0.523800                     0.000958   \n475                       0.439467                     0.002409   \n476                       0.476538                     0.002608   \n477                       0.247785                     0.000980   \n\n     original_ngtdm_Busyness  original_ngtdm_Coarseness  \\\n0                   0.007559                   0.022807   \n1                   0.013713                   0.012871   \n2                   0.769329                   0.000108   \n3                   0.056030                   0.003152   \n4                   0.010391                   0.016340   \n..                       ...                        ...   \n473                 0.070994                   0.005387   \n474                 0.045122                   0.004306   \n475                 0.011852                   0.016488   \n476                 0.032977                   0.011104   \n477                 0.036478                   0.005850   \n\n     original_ngtdm_Complexity  original_ngtdm_Contrast  \\\n0                     0.063422                 0.005191   \n1                     0.196799                 0.042580   \n2                     0.719984                 0.674811   \n3                     0.294172                 0.118040   \n4                     0.016220                 0.000263   \n..                         ...                      ...   \n473                   0.403776                 0.233790   \n474                   0.502312                 0.313650   \n475                   0.093852                 0.030622   \n476                   0.162008                 0.046136   \n477                   0.531386                 0.428874   \n\n     original_ngtdm_Strength  \n0                   0.065253  \n1                   0.039096  \n2                   0.000953  \n3                   0.010028  \n4                   0.055444  \n..                       ...  \n473                 0.016907  \n474                 0.013572  \n475                 0.049426  \n476                 0.033699  \n477                 0.019363  \n\n[478 rows x 118 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RelapseFreeSurvival (outcome)</th>\n      <th>Age</th>\n      <th>ER</th>\n      <th>PgR</th>\n      <th>HER2</th>\n      <th>TrippleNegative</th>\n      <th>ChemoGrade</th>\n      <th>Proliferation</th>\n      <th>HistologyType</th>\n      <th>LNStatus</th>\n      <th>...</th>\n      <th>original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n      <th>original_glszm_SmallAreaLowGrayLevelEmphasis</th>\n      <th>original_glszm_ZoneEntropy</th>\n      <th>original_glszm_ZonePercentage</th>\n      <th>original_glszm_ZoneVariance</th>\n      <th>original_ngtdm_Busyness</th>\n      <th>original_ngtdm_Coarseness</th>\n      <th>original_ngtdm_Complexity</th>\n      <th>original_ngtdm_Contrast</th>\n      <th>original_ngtdm_Strength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.456897</td>\n      <td>0.191874</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.651945</td>\n      <td>0.667335</td>\n      <td>0.323326</td>\n      <td>0.279340</td>\n      <td>0.003136</td>\n      <td>0.007559</td>\n      <td>0.022807</td>\n      <td>0.063422</td>\n      <td>0.005191</td>\n      <td>0.065253</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.775862</td>\n      <td>0.325517</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.530456</td>\n      <td>0.542978</td>\n      <td>0.470137</td>\n      <td>0.677938</td>\n      <td>0.000718</td>\n      <td>0.013713</td>\n      <td>0.012871</td>\n      <td>0.196799</td>\n      <td>0.042580</td>\n      <td>0.039096</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.482759</td>\n      <td>0.687807</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.417041</td>\n      <td>0.426887</td>\n      <td>0.562781</td>\n      <td>0.054941</td>\n      <td>0.081159</td>\n      <td>0.769329</td>\n      <td>0.000108</td>\n      <td>0.719984</td>\n      <td>0.674811</td>\n      <td>0.000953</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.043103</td>\n      <td>0.150089</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.347732</td>\n      <td>0.355941</td>\n      <td>0.570773</td>\n      <td>0.187794</td>\n      <td>0.006259</td>\n      <td>0.056030</td>\n      <td>0.003152</td>\n      <td>0.294172</td>\n      <td>0.118040</td>\n      <td>0.010028</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.715517</td>\n      <td>0.865464</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.558902</td>\n      <td>0.572096</td>\n      <td>0.404490</td>\n      <td>0.041034</td>\n      <td>0.114394</td>\n      <td>0.010391</td>\n      <td>0.016340</td>\n      <td>0.016220</td>\n      <td>0.000263</td>\n      <td>0.055444</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>473</th>\n      <td>0.757716</td>\n      <td>0.308502</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.953039</td>\n      <td>0.0</td>\n      <td>0.906077</td>\n      <td>...</td>\n      <td>0.091304</td>\n      <td>0.093459</td>\n      <td>0.700720</td>\n      <td>0.243464</td>\n      <td>0.004023</td>\n      <td>0.070994</td>\n      <td>0.005387</td>\n      <td>0.403776</td>\n      <td>0.233790</td>\n      <td>0.016907</td>\n    </tr>\n    <tr>\n      <th>474</th>\n      <td>0.454282</td>\n      <td>0.365053</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.757719</td>\n      <td>0.515437</td>\n      <td>0.0</td>\n      <td>0.515437</td>\n      <td>...</td>\n      <td>0.490071</td>\n      <td>0.501641</td>\n      <td>0.494613</td>\n      <td>0.523800</td>\n      <td>0.000958</td>\n      <td>0.045122</td>\n      <td>0.004306</td>\n      <td>0.502312</td>\n      <td>0.313650</td>\n      <td>0.013572</td>\n    </tr>\n    <tr>\n      <th>475</th>\n      <td>0.440622</td>\n      <td>0.358889</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.484302</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.619175</td>\n      <td>0.633792</td>\n      <td>0.362542</td>\n      <td>0.439467</td>\n      <td>0.002409</td>\n      <td>0.011852</td>\n      <td>0.016488</td>\n      <td>0.093852</td>\n      <td>0.030622</td>\n      <td>0.049426</td>\n    </tr>\n    <tr>\n      <th>476</th>\n      <td>0.407674</td>\n      <td>0.422152</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.406409</td>\n      <td>0.593591</td>\n      <td>0.500000</td>\n      <td>0.296796</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.628515</td>\n      <td>0.643353</td>\n      <td>0.410029</td>\n      <td>0.476538</td>\n      <td>0.002608</td>\n      <td>0.032977</td>\n      <td>0.011104</td>\n      <td>0.162008</td>\n      <td>0.046136</td>\n      <td>0.033699</td>\n    </tr>\n    <tr>\n      <th>477</th>\n      <td>0.292951</td>\n      <td>0.428162</td>\n      <td>0.508834</td>\n      <td>0.508834</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.245583</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.491166</td>\n      <td>...</td>\n      <td>0.200673</td>\n      <td>0.205409</td>\n      <td>0.487895</td>\n      <td>0.247785</td>\n      <td>0.000980</td>\n      <td>0.036478</td>\n      <td>0.005850</td>\n      <td>0.531386</td>\n      <td>0.428874</td>\n      <td>0.019363</td>\n    </tr>\n  </tbody>\n</table>\n<p>478 rows × 118 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "X_train[:]=scaler.fit_transform(X_train)\n",
    "X_test[:]=scaler.transform(X_test)\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def is_related(pair1, pair2):\n",
    "    if (pair1[0] in pair2 or pair1[1] in pair2) and pair1!=pair2 and not (pair1[0]==pair2[1] and pair1[1]==pair2[0]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def add_relation(corr_fea):\n",
    "    for i in range(len(corr_fea)):\n",
    "        for j in range(i,len(corr_fea)):\n",
    "            if i!=j:\n",
    "                if is_related(corr_fea[i],corr_fea[j]):\n",
    "                    fea1=tuple(set(corr_fea[i])-set(corr_fea[j]))\n",
    "                    fea2=tuple(set(corr_fea[j])-set(corr_fea[i]))\n",
    "                    fea=fea1+fea2\n",
    "                    if fea not in corr_fea and rev(fea) not in corr_fea:\n",
    "                        corr_fea.append((fea1+fea2))\n",
    "\n",
    "def rev(fea):\n",
    "    f1=fea[0]\n",
    "    f2=fea[1]\n",
    "\n",
    "    return (f2,f1)\n",
    "\n",
    "corr=X_train.corr()\n",
    "corr=corr.where(abs(corr)>0.9)\n",
    "count=0\n",
    "corr_fea=[]\n",
    "for i in corr.columns:\n",
    "    for j in corr.columns:\n",
    "        if i!=j and abs(corr[i][j])>0.9 and ((i,j) not in corr_fea) and ((j,i) not in corr_fea):\n",
    "            count+=1\n",
    "            corr_fea.append((i,j))\n",
    "            add_relation(corr_fea)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "new_num_fea=len(X_train.columns)-count\n",
    "\n",
    "pca=PCA(n_components=new_num_fea)\n",
    "X_train=pca.fit_transform(X_train)\n",
    "X_test=pca.transform(X_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.60251400e+00,  5.26448293e-01, -1.14385945e+00, ...,\n         4.50162474e-02, -7.54621442e-02,  3.70921755e-02],\n       [-7.75117033e-01,  1.12640966e-01, -1.05736880e+00, ...,\n         1.29125042e-01,  5.98241064e-03, -6.19482994e-03],\n       [ 2.07406523e+00, -7.59828866e-01,  5.99073837e-01, ...,\n         7.54495849e-02, -4.14135527e-02,  1.09935847e-01],\n       ...,\n       [-1.17600388e+00,  1.49667195e+00, -3.04448087e-01, ...,\n        -1.37052809e-01,  5.22002769e-02,  1.08727042e-02],\n       [-7.73878639e-01,  9.50926049e-01, -6.19307226e-02, ...,\n        -2.57383975e-01,  3.15928124e-02,  8.22453462e-05],\n       [ 1.50756239e+00, -3.56418341e-01,  4.06521016e-01, ...,\n        -3.57727552e-01,  1.23181565e-01, -2.11792916e-02]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "selector=SelectKBest(k=10)\n",
    "X_train=selector.fit_transform(X_train,y_train)\n",
    "X_test=selector.transform(X_test)\n",
    "X_train\n",
    "\n",
    "# from sklearn.feature_selection import S"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "# c=dataset.corr().abs()\n",
    "# s=c.unstack()\n",
    "# so=s.sort_values(kind=\"quicksort\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# delcol=[]\n",
    "# c=dataset.corr().shape[0]\n",
    "\n",
    "# names=dataset.corr().columns\n",
    "#\n",
    "# for i in range(c):\n",
    "#     for j in range(i+1,c):\n",
    "#         if dataset.corr().iloc[i,j]>0.8 :\n",
    "#             delcol.append((names[i],names[j]))\n",
    "# print(len(delcol))\n",
    "#\n",
    "# import numpy as np\n",
    "# np.a\n",
    "#\n",
    "# for i in range(c):\n",
    "#     count = 0\n",
    "#     for j in range(c):\n",
    "#         if dataset.corr().iloc[i,j]>0.8:\n",
    "#             count += 1\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76        60\n",
      "           1       0.35      0.47      0.40        19\n",
      "\n",
      "    accuracy                           0.66        79\n",
      "   macro avg       0.58      0.60      0.58        79\n",
      "weighted avg       0.70      0.66      0.67        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "clf=DecisionTreeClassifier(max_features=4,max_depth=5,class_weight='balanced')\n",
    "clf.fit(X_train,y_train)\n",
    "# clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,clf.predict(X_test)))\n",
    "# print(classification_report(y_train,clf.predict(X_train)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74        60\n",
      "           1       0.23      0.26      0.24        19\n",
      "\n",
      "    accuracy                           0.61        79\n",
      "   macro avg       0.49      0.49      0.49        79\n",
      "weighted avg       0.63      0.61      0.62        79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10253\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[235,   4],\n       [  0, 239]], dtype=int64)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf=MLPClassifier(hidden_layer_sizes=(12,23,40,12),activation=\"relu\",max_iter=200,batch_size=20)\n",
    "# cross_val_score(clf,X_train,y_train,cv=3)\n",
    "\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "print(classification_report(y_test,clf.predict(X_test)))\n",
    "confusion_matrix(y_train,clf.predict(X_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[48, 13],\n       [12,  6]], dtype=int64)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest=RandomForestClassifier(class_weight=\"balanced\")\n",
    "forest.fit(X_train,y_train)\n",
    "confusion_matrix(forest.predict(X_test),y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mle_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "059a28f6b8501a3f1855ad600b68ec92fe1ad87b13ae8c63d8d57e238add6b4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
