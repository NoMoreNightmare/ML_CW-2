{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "            ID  pCR (outcome)  RelapseFreeSurvival (outcome)   Age  ER  PgR  \\\n0    TRG002174              1                     144.000000  41.0   0  0.0   \n1    TRG002178              0                     142.000000  39.0   1  1.0   \n2    TRG002204              1                     135.000000  31.0   0  0.0   \n3    TRG002206              0                      12.000000  35.0   0  0.0   \n4    TRG002210              0                     109.000000  61.0   1  0.0   \n..         ...            ...                            ...   ...  ..  ...   \n395  TRG002955              1                      49.250000  46.1   0  0.0   \n396  TRG002958              0                      48.500000  53.3   0  0.0   \n397  TRG002961              0                      47.500000  68.8   1  0.0   \n398  TRG002962              0                      46.916667  46.0   1  0.0   \n399  TRG002963              1                      46.750000  55.3   0  0.0   \n\n     HER2  TrippleNegative  ChemoGrade  Proliferation  ...  \\\n0     0.0              1.0           3              3  ...   \n1     0.0              0.0           3              3  ...   \n2     0.0              1.0           2              1  ...   \n3     0.0              1.0           3              3  ...   \n4     0.0              0.0           2              1  ...   \n..    ...              ...         ...            ...  ...   \n395   0.0              1.0           3              3  ...   \n396   0.0              1.0           2              1  ...   \n397   0.0              0.0           3              3  ...   \n398   0.0              0.0           2              1  ...   \n399   1.0              0.0           2              1  ...   \n\n     original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n0                                         0.517172   \n1                                         0.444391   \n2                                         0.534549   \n3                                         0.506185   \n4                                         0.462282   \n..                                             ...   \n395                                       0.439568   \n396                                       0.527779   \n397                                       0.313693   \n398                                       0.670229   \n399                                       0.552491   \n\n     original_glszm_SmallAreaLowGrayLevelEmphasis  original_glszm_ZoneEntropy  \\\n0                                        0.375126                    3.325332   \n1                                        0.444391                    3.032144   \n2                                        0.534549                    2.485848   \n3                                        0.506185                    2.606255   \n4                                        0.462282                    2.809279   \n..                                            ...                         ...   \n395                                      0.439568                    3.056046   \n396                                      0.527778                    1.500000   \n397                                      0.313693                    3.573557   \n398                                      0.670229                    1.857045   \n399                                      0.552491                    2.671677   \n\n     original_glszm_ZonePercentage  original_glszm_ZoneVariance  \\\n0                         0.002314                 3.880772e+06   \n1                         0.005612                 2.372010e+06   \n2                         0.006752                 1.540027e+06   \n3                         0.003755                 6.936741e+06   \n4                         0.006521                 1.265399e+06   \n..                             ...                          ...   \n395                       0.001339                 1.671271e+07   \n396                       0.003728                 2.132007e+05   \n397                       0.001112                 2.008034e+07   \n398                       0.006706                 5.609262e+05   \n399                       0.005390                 1.570529e+06   \n\n     original_ngtdm_Busyness  original_ngtdm_Coarseness  \\\n0                 473.464852                   0.000768   \n1                  59.459710                   0.004383   \n2                  33.935384                   0.007584   \n3                  46.859265                   0.005424   \n4                  39.621023                   0.006585   \n..                       ...                        ...   \n395                79.989003                   0.003282   \n396                 0.996746                   0.252582   \n397               204.864200                   0.001372   \n398                 9.609163                   0.026591   \n399                72.281874                   0.003759   \n\n     original_ngtdm_Complexity  original_ngtdm_Contrast  \\\n0                     0.182615                 0.030508   \n1                     0.032012                 0.001006   \n2                     0.024062                 0.000529   \n3                     0.013707                 0.000178   \n4                     0.034148                 0.001083   \n..                         ...                      ...   \n395                   0.024716                 0.000812   \n396                   0.007380                 0.000037   \n397                   0.054063                 0.003697   \n398                   0.018682                 0.000311   \n399                   0.055151                 0.003054   \n\n     original_ngtdm_Strength  \n0                   0.000758  \n1                   0.003685  \n2                   0.006447  \n3                   0.004543  \n4                   0.005626  \n..                       ...  \n395                 0.003078  \n396                 0.231059  \n397                 0.001368  \n398                 0.022676  \n399                 0.003425  \n\n[395 rows x 120 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>pCR (outcome)</th>\n      <th>RelapseFreeSurvival (outcome)</th>\n      <th>Age</th>\n      <th>ER</th>\n      <th>PgR</th>\n      <th>HER2</th>\n      <th>TrippleNegative</th>\n      <th>ChemoGrade</th>\n      <th>Proliferation</th>\n      <th>...</th>\n      <th>original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n      <th>original_glszm_SmallAreaLowGrayLevelEmphasis</th>\n      <th>original_glszm_ZoneEntropy</th>\n      <th>original_glszm_ZonePercentage</th>\n      <th>original_glszm_ZoneVariance</th>\n      <th>original_ngtdm_Busyness</th>\n      <th>original_ngtdm_Coarseness</th>\n      <th>original_ngtdm_Complexity</th>\n      <th>original_ngtdm_Contrast</th>\n      <th>original_ngtdm_Strength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRG002174</td>\n      <td>1</td>\n      <td>144.000000</td>\n      <td>41.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.517172</td>\n      <td>0.375126</td>\n      <td>3.325332</td>\n      <td>0.002314</td>\n      <td>3.880772e+06</td>\n      <td>473.464852</td>\n      <td>0.000768</td>\n      <td>0.182615</td>\n      <td>0.030508</td>\n      <td>0.000758</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRG002178</td>\n      <td>0</td>\n      <td>142.000000</td>\n      <td>39.0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.444391</td>\n      <td>0.444391</td>\n      <td>3.032144</td>\n      <td>0.005612</td>\n      <td>2.372010e+06</td>\n      <td>59.459710</td>\n      <td>0.004383</td>\n      <td>0.032012</td>\n      <td>0.001006</td>\n      <td>0.003685</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRG002204</td>\n      <td>1</td>\n      <td>135.000000</td>\n      <td>31.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.534549</td>\n      <td>0.534549</td>\n      <td>2.485848</td>\n      <td>0.006752</td>\n      <td>1.540027e+06</td>\n      <td>33.935384</td>\n      <td>0.007584</td>\n      <td>0.024062</td>\n      <td>0.000529</td>\n      <td>0.006447</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRG002206</td>\n      <td>0</td>\n      <td>12.000000</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.506185</td>\n      <td>0.506185</td>\n      <td>2.606255</td>\n      <td>0.003755</td>\n      <td>6.936741e+06</td>\n      <td>46.859265</td>\n      <td>0.005424</td>\n      <td>0.013707</td>\n      <td>0.000178</td>\n      <td>0.004543</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRG002210</td>\n      <td>0</td>\n      <td>109.000000</td>\n      <td>61.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.462282</td>\n      <td>0.462282</td>\n      <td>2.809279</td>\n      <td>0.006521</td>\n      <td>1.265399e+06</td>\n      <td>39.621023</td>\n      <td>0.006585</td>\n      <td>0.034148</td>\n      <td>0.001083</td>\n      <td>0.005626</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>TRG002955</td>\n      <td>1</td>\n      <td>49.250000</td>\n      <td>46.1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.439568</td>\n      <td>0.439568</td>\n      <td>3.056046</td>\n      <td>0.001339</td>\n      <td>1.671271e+07</td>\n      <td>79.989003</td>\n      <td>0.003282</td>\n      <td>0.024716</td>\n      <td>0.000812</td>\n      <td>0.003078</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>TRG002958</td>\n      <td>0</td>\n      <td>48.500000</td>\n      <td>53.3</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.527779</td>\n      <td>0.527778</td>\n      <td>1.500000</td>\n      <td>0.003728</td>\n      <td>2.132007e+05</td>\n      <td>0.996746</td>\n      <td>0.252582</td>\n      <td>0.007380</td>\n      <td>0.000037</td>\n      <td>0.231059</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>TRG002961</td>\n      <td>0</td>\n      <td>47.500000</td>\n      <td>68.8</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.313693</td>\n      <td>0.313693</td>\n      <td>3.573557</td>\n      <td>0.001112</td>\n      <td>2.008034e+07</td>\n      <td>204.864200</td>\n      <td>0.001372</td>\n      <td>0.054063</td>\n      <td>0.003697</td>\n      <td>0.001368</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>TRG002962</td>\n      <td>0</td>\n      <td>46.916667</td>\n      <td>46.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.670229</td>\n      <td>0.670229</td>\n      <td>1.857045</td>\n      <td>0.006706</td>\n      <td>5.609262e+05</td>\n      <td>9.609163</td>\n      <td>0.026591</td>\n      <td>0.018682</td>\n      <td>0.000311</td>\n      <td>0.022676</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>TRG002963</td>\n      <td>1</td>\n      <td>46.750000</td>\n      <td>55.3</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.552491</td>\n      <td>0.552491</td>\n      <td>2.671677</td>\n      <td>0.005390</td>\n      <td>1.570529e+06</td>\n      <td>72.281874</td>\n      <td>0.003759</td>\n      <td>0.055151</td>\n      <td>0.003054</td>\n      <td>0.003425</td>\n    </tr>\n  </tbody>\n</table>\n<p>395 rows × 120 columns</p>\n</div>"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset=pd.read_excel(\"C:/Users/10253/Desktop/ML-CW-2/Data/trainDataset.xls\")\n",
    "dataset=dataset[dataset[\"pCR (outcome)\"]!=999]\n",
    "dataset.head(len(dataset))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "# from sklearn.impute import  SimpleImputer\n",
    "# imp=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "# names=dataset.columns.drop('ID')\n",
    "# a=imp.fit_transform(dataset.drop('ID',axis=1))\n",
    "# imp=SimpleImputer(missing_values=999,strategy='mean')\n",
    "# a=imp.fit_transform(a)\n",
    "# df=pd.DataFrame(a,columns=\n",
    "#                 names)\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Removing duplicate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "dataset.drop_duplicates(inplace=True) #because with 119 features, it is unlikely that exact same data happens in real world, it is useless for training and testing; hence remove it before dataset split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "0    299\n1     96\nName: pCR (outcome), dtype: int64"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['pCR (outcome)'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "y=dataset['pCR (outcome)']\n",
    "X=dataset.drop(['pCR (outcome)'],axis=1)\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,stratify=y,random_state=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### drop columns that are not applicable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "class columnDropperTransformer(): #https://stackoverflow.com/questions/68402691/adding-dropping-column-instance-into-a-pipeline\n",
    "    def __init__(self,columns):\n",
    "        self.columns=columns\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "        return X.drop(self.columns,axis=1)\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return X.drop(self.columns,axis=1)\n",
    "\n",
    "dropper = columnDropperTransformer(['ID'])\n",
    "X_train=dropper.fit_transform(X_train)\n",
    "\n",
    "X_test=dropper.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### missing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "ID                               0\npCR (outcome)                    0\nRelapseFreeSurvival (outcome)    0\nAge                              0\nER                               0\n                                ..\noriginal_ngtdm_Busyness          0\noriginal_ngtdm_Coarseness        0\noriginal_ngtdm_Complexity        0\noriginal_ngtdm_Contrast          0\noriginal_ngtdm_Strength          0\nLength: 120, dtype: int64"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "names=X_train.columns\n",
    "\n",
    "imp=KNNImputer(missing_values=np.nan,n_neighbors=10)\n",
    "# X_train[:]=imp.fit_transform(X_train)\n",
    "# X_test[:]=imp.transform(X_test)\n",
    "X_train=imp.fit_transform(X_train)\n",
    "X_test=imp.transform(X_test)\n",
    "\n",
    "imp.missing_values=np.float64(999)\n",
    "# X_train[:]=imp.fit_transform(X_train)\n",
    "# X_test[:]=imp.transform(X_test)\n",
    "X_train=imp.fit_transform(X_train)\n",
    "X_test=imp.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Removing outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# because use LocalOutlierFactor may lose useful information becuase whenever there is an outlier in any features of the sample, the sample will be detected as outlier sample and all its information will be set to 999\n",
    "# therefore, use other method\n",
    "\n",
    "class outlierHandlingWithDev():\n",
    "    def fit(self,X,y=None):\n",
    "        self.mean=np.zeros(len(X[0]))\n",
    "        self.std=np.zeros(len(X[0]))\n",
    "        for i in range(len(X[0])):\n",
    "            self.mean[i]=X[:,i].mean()\n",
    "            self.std[i]=X[:,i].std()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "        for i in range(len(X)):\n",
    "            for j in range(len(X[i])):\n",
    "                if np.abs(X[i][j]-self.mean[j])>3*self.std[j]:\n",
    "                    X[i][j]=999\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        self.fit(X,y)\n",
    "        return self.transform(X,y)\n",
    "    # def fit(self,X,y=None):\n",
    "    #     self.mean=X.mean(axis=0)\n",
    "    #     self.std=X.std(axis=0)\n",
    "    #\n",
    "    #     return self\n",
    "    #\n",
    "    # def transform(self,X,y=None):\n",
    "    #     for i in X.columns:\n",
    "    #         for j in range(len(X)):\n",
    "    #             if abs(X[i][j]-self.mean[i])>(3*self.std[i]):\n",
    "    #                 X[i][j]=999\n",
    "    #\n",
    "    #     return X\n",
    "    #\n",
    "    # def fit_transform(self,X,y=None):\n",
    "    #     self.fit(X,y)\n",
    "    #     return self.transform(X,y)\n",
    "\n",
    "detector=outlierHandlingWithDev()\n",
    "detector.fit(X_train)\n",
    "detector.transform(X_train)\n",
    "detector.transform(X_test)\n",
    "\n",
    "X_train=imp.fit_transform(X_train)\n",
    "X_test=imp.transform(X_test)\n",
    "\n",
    "X_train=pd.DataFrame(X_train,columns=names)\n",
    "X_test=pd.DataFrame(X_test,columns=names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Binning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### resample"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote=SMOTE()\n",
    "\n",
    "X_train,y_train=smote.fit_resample(X_train,y_train)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MinMaxScaler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "     RelapseFreeSurvival (outcome)       Age        ER       PgR      HER2  \\\n0                         0.370690  0.542087  0.000000  0.000000  0.000000   \n1                         0.741379  0.247337  0.000000  0.000000  0.000000   \n2                         0.767241  0.777344  1.000000  0.000000  1.000000   \n3                         0.129310  0.459340  0.000000  0.000000  0.000000   \n4                         0.387931  0.516790  1.000000  1.000000  0.000000   \n..                             ...       ...       ...       ...       ...   \n473                       0.409828  0.591029  0.000000  0.000000  0.400185   \n474                       0.291917  0.490428  0.030038  0.030038  0.030038   \n475                       0.378168  0.773216  0.000000  0.000000  0.000000   \n476                       0.381968  0.466615  0.198520  0.198520  0.198520   \n477                       0.606204  0.454662  0.995948  0.995948  0.995948   \n\n     TrippleNegative  ChemoGrade  Proliferation  HistologyType  LNStatus  ...  \\\n0           1.000000    0.500000       0.000000            0.0  0.000000  ...   \n1           1.000000    1.000000       1.000000            0.0  0.000000  ...   \n2           0.000000    0.500000       0.000000            0.0  0.000000  ...   \n3           1.000000    0.500000       0.000000            0.0  1.000000  ...   \n4           0.000000    0.500000       0.000000            0.0  1.000000  ...   \n..               ...         ...            ...            ...       ...  ...   \n473         0.599815    1.000000       0.700093            0.0  0.400185  ...   \n474         0.969962    0.515019       0.030038            0.0  1.000000  ...   \n475         1.000000    1.000000       0.500000            0.0  0.905624  ...   \n476         0.801480    0.599260       0.198520            0.0  1.000000  ...   \n477         0.004052    0.502026       0.004052            0.0  0.000000  ...   \n\n     original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n0                                         0.455968   \n1                                         0.432894   \n2                                         0.389308   \n3                                         0.546080   \n4                                         0.337877   \n..                                             ...   \n473                                       0.433183   \n474                                       0.592461   \n475                                       0.101955   \n476                                       0.494050   \n477                                       0.578543   \n\n     original_glszm_SmallAreaLowGrayLevelEmphasis  original_glszm_ZoneEntropy  \\\n0                                        0.460253                    0.638994   \n1                                        0.436964                    0.546212   \n2                                        0.392968                    0.563218   \n3                                        0.551214                    0.513451   \n4                                        0.341053                    0.757515   \n..                                            ...                         ...   \n473                                      0.437255                    0.485163   \n474                                      0.598030                    0.224649   \n475                                      0.102913                    0.458954   \n476                                      0.498695                    0.315029   \n477                                      0.583980                    0.275804   \n\n     original_glszm_ZonePercentage  original_glszm_ZoneVariance  \\\n0                         0.587399                     0.003439   \n1                         0.127545                     0.020124   \n2                         0.022627                     0.721885   \n3                         0.241711                     0.010123   \n4                         0.551796                     0.001268   \n..                             ...                          ...   \n473                       0.422396                     0.000912   \n474                       0.150738                     0.002628   \n475                       0.294714                     0.000795   \n476                       0.169256                     0.002865   \n477                       0.689531                     0.000160   \n\n     original_ngtdm_Busyness  original_ngtdm_Coarseness  \\\n0                   0.067796                   0.002780   \n1                   0.033764                   0.005696   \n2                   0.036499                   0.005139   \n3                   0.044997                   0.004215   \n4                   0.107620                   0.001713   \n..                       ...                        ...   \n473                 0.087474                   0.002994   \n474                 0.003706                   0.182378   \n475                 0.049888                   0.005152   \n476                 0.018615                   0.151092   \n477                 0.012275                   0.018386   \n\n     original_ngtdm_Complexity  original_ngtdm_Contrast  \\\n0                     0.212187                 0.046105   \n1                     0.088502                 0.008232   \n2                     0.015420                 0.000211   \n3                     0.105641                 0.011536   \n4                     0.315393                 0.107677   \n..                         ...                      ...   \n473                   0.780283                 0.755564   \n474                   0.028214                 0.007319   \n475                   0.690485                 0.597317   \n476                   0.100124                 0.047363   \n477                   0.482934                 0.268679   \n\n     original_ngtdm_Strength  \n0                   0.009190  \n1                   0.020419  \n2                   0.018433  \n3                   0.014063  \n4                   0.006009  \n..                       ...  \n473                 0.010471  \n474                 0.588373  \n475                 0.016790  \n476                 0.487550  \n477                 0.057633  \n\n[478 rows x 118 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RelapseFreeSurvival (outcome)</th>\n      <th>Age</th>\n      <th>ER</th>\n      <th>PgR</th>\n      <th>HER2</th>\n      <th>TrippleNegative</th>\n      <th>ChemoGrade</th>\n      <th>Proliferation</th>\n      <th>HistologyType</th>\n      <th>LNStatus</th>\n      <th>...</th>\n      <th>original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n      <th>original_glszm_SmallAreaLowGrayLevelEmphasis</th>\n      <th>original_glszm_ZoneEntropy</th>\n      <th>original_glszm_ZonePercentage</th>\n      <th>original_glszm_ZoneVariance</th>\n      <th>original_ngtdm_Busyness</th>\n      <th>original_ngtdm_Coarseness</th>\n      <th>original_ngtdm_Complexity</th>\n      <th>original_ngtdm_Contrast</th>\n      <th>original_ngtdm_Strength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.370690</td>\n      <td>0.542087</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.455968</td>\n      <td>0.460253</td>\n      <td>0.638994</td>\n      <td>0.587399</td>\n      <td>0.003439</td>\n      <td>0.067796</td>\n      <td>0.002780</td>\n      <td>0.212187</td>\n      <td>0.046105</td>\n      <td>0.009190</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.741379</td>\n      <td>0.247337</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.432894</td>\n      <td>0.436964</td>\n      <td>0.546212</td>\n      <td>0.127545</td>\n      <td>0.020124</td>\n      <td>0.033764</td>\n      <td>0.005696</td>\n      <td>0.088502</td>\n      <td>0.008232</td>\n      <td>0.020419</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.767241</td>\n      <td>0.777344</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.389308</td>\n      <td>0.392968</td>\n      <td>0.563218</td>\n      <td>0.022627</td>\n      <td>0.721885</td>\n      <td>0.036499</td>\n      <td>0.005139</td>\n      <td>0.015420</td>\n      <td>0.000211</td>\n      <td>0.018433</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.129310</td>\n      <td>0.459340</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.546080</td>\n      <td>0.551214</td>\n      <td>0.513451</td>\n      <td>0.241711</td>\n      <td>0.010123</td>\n      <td>0.044997</td>\n      <td>0.004215</td>\n      <td>0.105641</td>\n      <td>0.011536</td>\n      <td>0.014063</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.387931</td>\n      <td>0.516790</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.337877</td>\n      <td>0.341053</td>\n      <td>0.757515</td>\n      <td>0.551796</td>\n      <td>0.001268</td>\n      <td>0.107620</td>\n      <td>0.001713</td>\n      <td>0.315393</td>\n      <td>0.107677</td>\n      <td>0.006009</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>473</th>\n      <td>0.409828</td>\n      <td>0.591029</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.400185</td>\n      <td>0.599815</td>\n      <td>1.000000</td>\n      <td>0.700093</td>\n      <td>0.0</td>\n      <td>0.400185</td>\n      <td>...</td>\n      <td>0.433183</td>\n      <td>0.437255</td>\n      <td>0.485163</td>\n      <td>0.422396</td>\n      <td>0.000912</td>\n      <td>0.087474</td>\n      <td>0.002994</td>\n      <td>0.780283</td>\n      <td>0.755564</td>\n      <td>0.010471</td>\n    </tr>\n    <tr>\n      <th>474</th>\n      <td>0.291917</td>\n      <td>0.490428</td>\n      <td>0.030038</td>\n      <td>0.030038</td>\n      <td>0.030038</td>\n      <td>0.969962</td>\n      <td>0.515019</td>\n      <td>0.030038</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.592461</td>\n      <td>0.598030</td>\n      <td>0.224649</td>\n      <td>0.150738</td>\n      <td>0.002628</td>\n      <td>0.003706</td>\n      <td>0.182378</td>\n      <td>0.028214</td>\n      <td>0.007319</td>\n      <td>0.588373</td>\n    </tr>\n    <tr>\n      <th>475</th>\n      <td>0.378168</td>\n      <td>0.773216</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.905624</td>\n      <td>...</td>\n      <td>0.101955</td>\n      <td>0.102913</td>\n      <td>0.458954</td>\n      <td>0.294714</td>\n      <td>0.000795</td>\n      <td>0.049888</td>\n      <td>0.005152</td>\n      <td>0.690485</td>\n      <td>0.597317</td>\n      <td>0.016790</td>\n    </tr>\n    <tr>\n      <th>476</th>\n      <td>0.381968</td>\n      <td>0.466615</td>\n      <td>0.198520</td>\n      <td>0.198520</td>\n      <td>0.198520</td>\n      <td>0.801480</td>\n      <td>0.599260</td>\n      <td>0.198520</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.494050</td>\n      <td>0.498695</td>\n      <td>0.315029</td>\n      <td>0.169256</td>\n      <td>0.002865</td>\n      <td>0.018615</td>\n      <td>0.151092</td>\n      <td>0.100124</td>\n      <td>0.047363</td>\n      <td>0.487550</td>\n    </tr>\n    <tr>\n      <th>477</th>\n      <td>0.606204</td>\n      <td>0.454662</td>\n      <td>0.995948</td>\n      <td>0.995948</td>\n      <td>0.995948</td>\n      <td>0.004052</td>\n      <td>0.502026</td>\n      <td>0.004052</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.578543</td>\n      <td>0.583980</td>\n      <td>0.275804</td>\n      <td>0.689531</td>\n      <td>0.000160</td>\n      <td>0.012275</td>\n      <td>0.018386</td>\n      <td>0.482934</td>\n      <td>0.268679</td>\n      <td>0.057633</td>\n    </tr>\n  </tbody>\n</table>\n<p>478 rows × 118 columns</p>\n</div>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "X_train[:]=scaler.fit_transform(X_train)\n",
    "X_test[:]=scaler.transform(X_test)\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "def is_related(pair1, pair2):\n",
    "    if (pair1[0] in pair2 or pair1[1] in pair2) and pair1!=pair2 and not (pair1[0]==pair2[1] and pair1[1]==pair2[0]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def add_relation(corr_fea):\n",
    "    for i in range(len(corr_fea)):\n",
    "        for j in range(i,len(corr_fea)):\n",
    "            if i!=j:\n",
    "                if is_related(corr_fea[i],corr_fea[j]):\n",
    "                    fea1=tuple(set(corr_fea[i])-set(corr_fea[j]))\n",
    "                    fea2=tuple(set(corr_fea[j])-set(corr_fea[i]))\n",
    "                    fea=fea1+fea2\n",
    "                    if fea not in corr_fea and rev(fea) not in corr_fea:\n",
    "                        corr_fea.append((fea1+fea2))\n",
    "\n",
    "def rev(fea):\n",
    "    f1=fea[0]\n",
    "    f2=fea[1]\n",
    "\n",
    "    return (f2,f1)\n",
    "\n",
    "corr=X_train.corr()\n",
    "corr=corr.where(abs(corr)>0.9)\n",
    "count=0\n",
    "corr_fea=[]\n",
    "for i in corr.columns:\n",
    "    for j in corr.columns:\n",
    "        if i!=j and abs(corr[i][j])>0.9 and ((i,j) not in corr_fea) and ((j,i) not in corr_fea):\n",
    "            count+=1\n",
    "            corr_fea.append((i,j))\n",
    "            add_relation(corr_fea)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "new_num_fea=len(X_train.columns)-count\n",
    "\n",
    "pca=PCA(n_components=new_num_fea)\n",
    "X_train=pca.fit_transform(X_train)\n",
    "X_test=pca.transform(X_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-4.35381412e-01,  1.09358880e-01,  5.88588002e-01, ...,\n        -7.63587318e-03, -7.10771208e-03, -2.95793265e-02],\n       [-1.03724378e+00,  3.23960533e-01,  1.26919693e+00, ...,\n         2.50070012e-02, -2.55934937e-02, -5.69553311e-02],\n       [-2.47742268e+00,  1.51527950e+00, -4.22775172e-01, ...,\n        -9.11002724e-02, -4.96205702e-02,  2.78973442e-02],\n       ...,\n       [ 2.29170429e+00, -3.77099481e-01,  7.19067268e-01, ...,\n         1.34276178e-02, -3.50646136e-02, -1.99981715e-02],\n       [-9.08768481e-01, -1.21430527e+00,  1.22266588e+00, ...,\n         2.96633966e-02, -1.38802275e-02,  4.16677115e-02],\n       [ 1.00276930e+00, -1.73693065e+00, -7.03053680e-01, ...,\n        -4.22872383e-02, -5.45876039e-03,  1.94340175e-03]])"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "selector=RFECV(SVC(kernel=\"linear\"),step=2000,min_features_to_select=10)\n",
    "X_train=selector.fit_transform(X_train,y_train)\n",
    "X_test=selector.transform(X_test)\n",
    "X_train\n",
    "\n",
    "# from sklearn.feature_selection import S"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "\n",
    "# c=dataset.corr().abs()\n",
    "# s=c.unstack()\n",
    "# so=s.sort_values(kind=\"quicksort\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# delcol=[]\n",
    "# c=dataset.corr().shape[0]\n",
    "\n",
    "# names=dataset.corr().columns\n",
    "#\n",
    "# for i in range(c):\n",
    "#     for j in range(i+1,c):\n",
    "#         if dataset.corr().iloc[i,j]>0.8 :\n",
    "#             delcol.append((names[i],names[j]))\n",
    "# print(len(delcol))\n",
    "#\n",
    "# import numpy as np\n",
    "# np.a\n",
    "#\n",
    "# for i in range(c):\n",
    "#     count = 0\n",
    "#     for j in range(c):\n",
    "#         if dataset.corr().iloc[i,j]>0.8:\n",
    "#             count += 1\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.42      0.54        60\n",
      "           1       0.24      0.58      0.34        19\n",
      "\n",
      "    accuracy                           0.46        79\n",
      "   macro avg       0.50      0.50      0.44        79\n",
      "weighted avg       0.63      0.46      0.49        79\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[25, 35],\n       [ 8, 11]], dtype=int64)"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "clf=DecisionTreeClassifier(max_features=4,max_depth=5,class_weight='balanced')\n",
    "clf.fit(X_train,y_train)\n",
    "# clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,clf.predict(X_test)))\n",
    "# print(classification_report(y_train,clf.predict(X_train)))\n",
    "confusion_matrix(y_test,clf.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87        60\n",
      "           1       0.60      0.47      0.53        19\n",
      "\n",
      "    accuracy                           0.80        79\n",
      "   macro avg       0.72      0.69      0.70        79\n",
      "weighted avg       0.79      0.80      0.79        79\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[239,   0],\n       [  0, 239]], dtype=int64)"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf=MLPClassifier(hidden_layer_sizes=(12,40),activation=\"relu\",max_iter=200,batch_size=20)\n",
    "# cross_val_score(clf,X_train,y_train,cv=3)\n",
    "\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "print(classification_report(y_test,clf.predict(X_test)))\n",
    "confusion_matrix(y_test,clf.predict(X_test))\n",
    "confusion_matrix(y_train,clf.predict(X_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[55, 17],\n       [ 5,  2]], dtype=int64)"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest=RandomForestClassifier(class_weight=\"balanced\")\n",
    "forest.fit(X_train,y_train)\n",
    "confusion_matrix(forest.predict(X_test),y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# clf=MLPClassifier(hidden_layer_sizes=(12,40,23,30),activation=\"relu\",max_iter=500,batch_size=20)\n",
    "# # cross_val_score(clf,X_train,y_train,cv=3)\n",
    "# from sklearn.feature_selection import SequentialFeatureSelector\n",
    "# sfs=SequentialFeatureSelector(clf,n_features_to_select=\"auto\")\n",
    "#\n",
    "# sfs.fit(X_train,y_train)\n",
    "# print(classification_report(y_test,sfs.predict(X_test)))\n",
    "# confusion_matrix(y_test,sfs.predict(X_test))\n",
    "# confusion_matrix(y_train,sfs.predict(X_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mle_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "059a28f6b8501a3f1855ad600b68ec92fe1ad87b13ae8c63d8d57e238add6b4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
