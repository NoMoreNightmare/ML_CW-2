{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            ID  pCR (outcome)  RelapseFreeSurvival (outcome)   Age  ER  PgR  \\\n0    TRG002174              1                     144.000000  41.0   0    0   \n1    TRG002178              0                     142.000000  39.0   1    1   \n2    TRG002204              1                     135.000000  31.0   0    0   \n3    TRG002206              0                      12.000000  35.0   0    0   \n4    TRG002210              0                     109.000000  61.0   1    0   \n..         ...            ...                            ...   ...  ..  ...   \n395  TRG002955              1                      49.250000  46.1   0    0   \n396  TRG002958              0                      48.500000  53.3   0    0   \n397  TRG002961              0                      47.500000  68.8   1    0   \n398  TRG002962              0                      46.916667  46.0   1    0   \n399  TRG002963              1                      46.750000  55.3   0    0   \n\n     HER2  TrippleNegative  ChemoGrade  Proliferation  ...  \\\n0       0                1           3              3  ...   \n1       0                0           3              3  ...   \n2       0                1           2              1  ...   \n3       0                1           3              3  ...   \n4       0                0           2              1  ...   \n..    ...              ...         ...            ...  ...   \n395     0                1           3              3  ...   \n396     0                1           2              1  ...   \n397     0                0           3              3  ...   \n398     0                0           2              1  ...   \n399     1                0           2              1  ...   \n\n     original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n0                                         0.517172   \n1                                         0.444391   \n2                                         0.534549   \n3                                         0.506185   \n4                                         0.462282   \n..                                             ...   \n395                                       0.439568   \n396                                       0.527779   \n397                                       0.313693   \n398                                       0.670229   \n399                                       0.552491   \n\n     original_glszm_SmallAreaLowGrayLevelEmphasis  original_glszm_ZoneEntropy  \\\n0                                        0.375126                    3.325332   \n1                                        0.444391                    3.032144   \n2                                        0.534549                    2.485848   \n3                                        0.506185                    2.606255   \n4                                        0.462282                    2.809279   \n..                                            ...                         ...   \n395                                      0.439568                    3.056046   \n396                                      0.527778                    1.500000   \n397                                      0.313693                    3.573557   \n398                                      0.670229                    1.857045   \n399                                      0.552491                    2.671677   \n\n     original_glszm_ZonePercentage  original_glszm_ZoneVariance  \\\n0                         0.002314                 3.880772e+06   \n1                         0.005612                 2.372010e+06   \n2                         0.006752                 1.540027e+06   \n3                         0.003755                 6.936741e+06   \n4                         0.006521                 1.265399e+06   \n..                             ...                          ...   \n395                       0.001339                 1.671271e+07   \n396                       0.003728                 2.132007e+05   \n397                       0.001112                 2.008034e+07   \n398                       0.006706                 5.609262e+05   \n399                       0.005390                 1.570529e+06   \n\n     original_ngtdm_Busyness  original_ngtdm_Coarseness  \\\n0                 473.464852                   0.000768   \n1                  59.459710                   0.004383   \n2                  33.935384                   0.007584   \n3                  46.859265                   0.005424   \n4                  39.621023                   0.006585   \n..                       ...                        ...   \n395                79.989003                   0.003282   \n396                 0.996746                   0.252582   \n397               204.864200                   0.001372   \n398                 9.609163                   0.026591   \n399                72.281874                   0.003759   \n\n     original_ngtdm_Complexity  original_ngtdm_Contrast  \\\n0                     0.182615                 0.030508   \n1                     0.032012                 0.001006   \n2                     0.024062                 0.000529   \n3                     0.013707                 0.000178   \n4                     0.034148                 0.001083   \n..                         ...                      ...   \n395                   0.024716                 0.000812   \n396                   0.007380                 0.000037   \n397                   0.054063                 0.003697   \n398                   0.018682                 0.000311   \n399                   0.055151                 0.003054   \n\n     original_ngtdm_Strength  \n0                   0.000758  \n1                   0.003685  \n2                   0.006447  \n3                   0.004543  \n4                   0.005626  \n..                       ...  \n395                 0.003078  \n396                 0.231059  \n397                 0.001368  \n398                 0.022676  \n399                 0.003425  \n\n[400 rows x 120 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>pCR (outcome)</th>\n      <th>RelapseFreeSurvival (outcome)</th>\n      <th>Age</th>\n      <th>ER</th>\n      <th>PgR</th>\n      <th>HER2</th>\n      <th>TrippleNegative</th>\n      <th>ChemoGrade</th>\n      <th>Proliferation</th>\n      <th>...</th>\n      <th>original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n      <th>original_glszm_SmallAreaLowGrayLevelEmphasis</th>\n      <th>original_glszm_ZoneEntropy</th>\n      <th>original_glszm_ZonePercentage</th>\n      <th>original_glszm_ZoneVariance</th>\n      <th>original_ngtdm_Busyness</th>\n      <th>original_ngtdm_Coarseness</th>\n      <th>original_ngtdm_Complexity</th>\n      <th>original_ngtdm_Contrast</th>\n      <th>original_ngtdm_Strength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRG002174</td>\n      <td>1</td>\n      <td>144.000000</td>\n      <td>41.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.517172</td>\n      <td>0.375126</td>\n      <td>3.325332</td>\n      <td>0.002314</td>\n      <td>3.880772e+06</td>\n      <td>473.464852</td>\n      <td>0.000768</td>\n      <td>0.182615</td>\n      <td>0.030508</td>\n      <td>0.000758</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRG002178</td>\n      <td>0</td>\n      <td>142.000000</td>\n      <td>39.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.444391</td>\n      <td>0.444391</td>\n      <td>3.032144</td>\n      <td>0.005612</td>\n      <td>2.372010e+06</td>\n      <td>59.459710</td>\n      <td>0.004383</td>\n      <td>0.032012</td>\n      <td>0.001006</td>\n      <td>0.003685</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRG002204</td>\n      <td>1</td>\n      <td>135.000000</td>\n      <td>31.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.534549</td>\n      <td>0.534549</td>\n      <td>2.485848</td>\n      <td>0.006752</td>\n      <td>1.540027e+06</td>\n      <td>33.935384</td>\n      <td>0.007584</td>\n      <td>0.024062</td>\n      <td>0.000529</td>\n      <td>0.006447</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRG002206</td>\n      <td>0</td>\n      <td>12.000000</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.506185</td>\n      <td>0.506185</td>\n      <td>2.606255</td>\n      <td>0.003755</td>\n      <td>6.936741e+06</td>\n      <td>46.859265</td>\n      <td>0.005424</td>\n      <td>0.013707</td>\n      <td>0.000178</td>\n      <td>0.004543</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRG002210</td>\n      <td>0</td>\n      <td>109.000000</td>\n      <td>61.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.462282</td>\n      <td>0.462282</td>\n      <td>2.809279</td>\n      <td>0.006521</td>\n      <td>1.265399e+06</td>\n      <td>39.621023</td>\n      <td>0.006585</td>\n      <td>0.034148</td>\n      <td>0.001083</td>\n      <td>0.005626</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>TRG002955</td>\n      <td>1</td>\n      <td>49.250000</td>\n      <td>46.1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.439568</td>\n      <td>0.439568</td>\n      <td>3.056046</td>\n      <td>0.001339</td>\n      <td>1.671271e+07</td>\n      <td>79.989003</td>\n      <td>0.003282</td>\n      <td>0.024716</td>\n      <td>0.000812</td>\n      <td>0.003078</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>TRG002958</td>\n      <td>0</td>\n      <td>48.500000</td>\n      <td>53.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.527779</td>\n      <td>0.527778</td>\n      <td>1.500000</td>\n      <td>0.003728</td>\n      <td>2.132007e+05</td>\n      <td>0.996746</td>\n      <td>0.252582</td>\n      <td>0.007380</td>\n      <td>0.000037</td>\n      <td>0.231059</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>TRG002961</td>\n      <td>0</td>\n      <td>47.500000</td>\n      <td>68.8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.313693</td>\n      <td>0.313693</td>\n      <td>3.573557</td>\n      <td>0.001112</td>\n      <td>2.008034e+07</td>\n      <td>204.864200</td>\n      <td>0.001372</td>\n      <td>0.054063</td>\n      <td>0.003697</td>\n      <td>0.001368</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>TRG002962</td>\n      <td>0</td>\n      <td>46.916667</td>\n      <td>46.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.670229</td>\n      <td>0.670229</td>\n      <td>1.857045</td>\n      <td>0.006706</td>\n      <td>5.609262e+05</td>\n      <td>9.609163</td>\n      <td>0.026591</td>\n      <td>0.018682</td>\n      <td>0.000311</td>\n      <td>0.022676</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>TRG002963</td>\n      <td>1</td>\n      <td>46.750000</td>\n      <td>55.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.552491</td>\n      <td>0.552491</td>\n      <td>2.671677</td>\n      <td>0.005390</td>\n      <td>1.570529e+06</td>\n      <td>72.281874</td>\n      <td>0.003759</td>\n      <td>0.055151</td>\n      <td>0.003054</td>\n      <td>0.003425</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 120 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset=pd.read_excel(\"C:/Users/10253/Desktop/ML-CW-2/Data/trainDataset.xls\")\n",
    "dataset=dataset[dataset[\"RelapseFreeSurvival (outcome)\"]!=999]\n",
    "dataset.head(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset.drop_duplicates(inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "y=dataset['RelapseFreeSurvival (outcome)']\n",
    "X=dataset.drop(['pCR (outcome)','RelapseFreeSurvival (outcome)'],axis=1)\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class columnDropperTransformer(): #https://stackoverflow.com/questions/68402691/adding-dropping-column-instance-into-a-pipeline\n",
    "    def __init__(self,columns):\n",
    "        self.columns=columns\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "        return X.drop(self.columns,axis=1)\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return X.drop(self.columns,axis=1)\n",
    "\n",
    "dropper = columnDropperTransformer(['ID'])\n",
    "X_train=dropper.fit_transform(X_train)\n",
    "\n",
    "X_test=dropper.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "ID                               0\npCR (outcome)                    0\nRelapseFreeSurvival (outcome)    0\nAge                              0\nER                               0\n                                ..\noriginal_ngtdm_Busyness          0\noriginal_ngtdm_Coarseness        0\noriginal_ngtdm_Complexity        0\noriginal_ngtdm_Contrast          0\noriginal_ngtdm_Strength          0\nLength: 120, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "names=X_train.columns\n",
    "\n",
    "imp=KNNImputer(missing_values=np.nan,n_neighbors=200)\n",
    "X_train=imp.fit_transform(X_train)\n",
    "X_test=imp.transform(X_test)\n",
    "\n",
    "imp.missing_values=np.float64(999)\n",
    "X_train=imp.fit_transform(X_train)\n",
    "X_test=imp.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class outlierHandlingWithDev():\n",
    "    def fit(self,X,y=None):\n",
    "        self.mean=np.zeros(len(X[0]))\n",
    "        self.std=np.zeros(len(X[0]))\n",
    "        for i in range(len(X[0])):\n",
    "            self.mean[i]=X[:,i].mean()\n",
    "            self.std[i]=X[:,i].std()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "        for i in range(len(X)):\n",
    "            for j in range(len(X[i])):\n",
    "                if np.abs(X[i][j]-self.mean[j])>2*self.std[j]:\n",
    "                    X[i][j]=999\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        self.fit(X,y)\n",
    "        return self.transform(X,y)\n",
    "\n",
    "# detector=outlierHandlingWithDev()\n",
    "# detector.fit(X_train)\n",
    "# detector.transform(X_train)\n",
    "# detector.transform(X_test)\n",
    "#\n",
    "# X_train=imp.fit_transform(X_train)\n",
    "# X_test=imp.transform(X_test)\n",
    "\n",
    "X_train=pd.DataFrame(X_train,columns=names)\n",
    "X_test=pd.DataFrame(X_test,columns=names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import KBinsDiscretizer\n",
    "# datasetCopy=dataset.iloc[:,3].values.reshape(-1,1)\n",
    "# # 不能导入一维，所以reshape\n",
    "# est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')\n",
    "# est.fit(datasetCopy)\n",
    "# Xt = est.transform(datasetCopy)\n",
    "# set(Xt.ravel())\n",
    "# dataset.iloc[:,3]=Xt\n",
    "# dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_train[:]=scaler.fit_transform(X_train)\n",
    "X_test[:]=scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "82"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr=X_train.corr()\n",
    "corr=corr.where(abs(corr)>0.9)\n",
    "count = 0\n",
    "corr_fea = []\n",
    "\n",
    "for i in corr.columns:\n",
    "    for j in corr.columns:\n",
    "        if abs(corr[i][j])>0.9 and i!=j:\n",
    "            if i not in corr_fea:\n",
    "                count+=1\n",
    "                corr_fea.append(i)\n",
    "\n",
    "            if j not in corr_fea:\n",
    "                count+=1\n",
    "                corr_fea.append(j)\n",
    "\n",
    "count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def is_related(pair1, pair2):\n",
    "    if (pair1[0] in pair2 or pair1[1] in pair2) and pair1!=pair2 and not (pair1[0]==pair2[1] and pair1[1]==pair2[0]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def add_relation(corr_fea):\n",
    "    for i in range(len(corr_fea)):\n",
    "        for j in range(i,len(corr_fea)):\n",
    "            if i!=j:\n",
    "                if is_related(corr_fea[i],corr_fea[j]):\n",
    "                    fea1=tuple(set(corr_fea[i])-set(corr_fea[j]))\n",
    "                    fea2=tuple(set(corr_fea[j])-set(corr_fea[i]))\n",
    "                    fea=fea1+fea2\n",
    "                    if fea not in corr_fea and rev(fea) not in corr_fea:\n",
    "                        corr_fea.append((fea1+fea2))\n",
    "\n",
    "def rev(fea):\n",
    "    f1=fea[0]\n",
    "    f2=fea[1]\n",
    "\n",
    "    return (f2,f1)\n",
    "\n",
    "corr=X_train.corr()\n",
    "corr=corr.where(abs(corr)>0.9)\n",
    "count=0\n",
    "corr_fea=[]\n",
    "for i in corr.columns:\n",
    "    for j in corr.columns:\n",
    "        if i!=j and abs(corr[i][j])>0.9 and ((i,j) not in corr_fea) and ((j,i) not in corr_fea):\n",
    "            count+=1\n",
    "            corr_fea.append((i,j))\n",
    "            add_relation(corr_fea)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "new_num_fea=len(X_train.columns)-count\n",
    "\n",
    "pca=PCA(n_components=new_num_fea)\n",
    "X_train=pca.fit_transform(X_train)\n",
    "X_test=pca.transform(X_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.91352173398952\n",
      "19.74543757427465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "regressor=MLPRegressor(hidden_layer_sizes=(50,100,70),activation=\"relu\",random_state=1,max_iter=1000,early_stopping=True)\n",
    "regressor.fit(X_train,y_train)\n",
    "y_pred=regressor.predict(X_test)\n",
    "err=mean_absolute_error(y_pred,y_test)\n",
    "print(err)\n",
    "err=mean_absolute_error(regressor.predict(X_train),y_train)\n",
    "print(err)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-24-ea93433bd5e9>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msvm\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLinearSVR\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mregressor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mLinearSVR\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepsilon\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.05\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmax_iter\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5000\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mC\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdual\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mregressor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mregressor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmean_absolute_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    487\u001B[0m         )\n\u001B[0;32m    488\u001B[0m         \u001B[0mpenalty\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"l2\"\u001B[0m  \u001B[1;31m# SVR only accepts l2 penalty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 489\u001B[1;33m         self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n\u001B[0m\u001B[0;32m    490\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    491\u001B[0m             \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001B[0m in \u001B[0;36m_fit_liblinear\u001B[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001B[0m\n\u001B[0;32m   1202\u001B[0m     \u001B[0msample_weight\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_check_sample_weight\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1203\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1204\u001B[1;33m     \u001B[0msolver_type\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_get_liblinear_solver_type\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmulti_class\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpenalty\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdual\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1205\u001B[0m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001B[0;32m   1206\u001B[0m         \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001B[0m in \u001B[0;36m_get_liblinear_solver_type\u001B[1;34m(multi_class, penalty, loss, dual)\u001B[0m\n\u001B[0;32m   1041\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0msolver_num\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1043\u001B[1;33m     raise ValueError(\n\u001B[0m\u001B[0;32m   1044\u001B[0m         \u001B[1;34m\"Unsupported set of arguments: %s, Parameters: penalty=%r, loss=%r, dual=%r\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1045\u001B[0m         \u001B[1;33m%\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0merror_string\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpenalty\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdual\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "regressor=LinearSVR(max_iter=5000,C=1)\n",
    "regressor.fit(X_train,y_train)\n",
    "y_pred=regressor.predict(X_test)\n",
    "err=mean_absolute_error(y_pred,y_test)\n",
    "print(err)\n",
    "err=mean_absolute_error(regressor.predict(X_train),y_train)\n",
    "print(err)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%from\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
